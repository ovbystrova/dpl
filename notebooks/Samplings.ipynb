{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Samplings.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_atl3QDIkua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install alchemy-catalyst\n",
        "!pip install transformers\n",
        "!pip install -U catalyst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_Tg7f4FI4fZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jurPJymII6jD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46a79b0a-ed36-413d-ba11-c6a7752140d6"
      },
      "source": [
        "import os\n",
        "import wandb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext  import data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "import catalyst.dl as dl\n",
        "from collections import OrderedDict\n",
        "from catalyst.dl.callbacks  import AccuracyCallback, EarlyStoppingCallback, WandbLogger\n",
        "\n",
        "from transformers import BertTokenizer, BertModel, GPT2Model, GPT2Tokenizer\n",
        "from tokenizers import SentencePieceBPETokenizer\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj4u01_UQow0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAMPLING = 'argmax' # temperature, nucleus, top_k, argmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih72GdOHRCT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b7a9430-fd63-4bf4-f570-71da1e8300b1"
      },
      "source": [
        "# uncomment if google colab:\n",
        " \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/')\n",
        "\n",
        "df = pd.read_csv(\"data/sampling_same_{}.csv\".format(SAMPLING))"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4FE4tH1RHJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "25bab115-eef2-49d5-a618-36344d3573d9"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sampling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55063</th>\n",
              "      <td>WASHINGTON, June 1 (Reuters) - U.S. constructi...</td>\n",
              "      <td>fake</td>\n",
              "      <td>argmax</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55064</th>\n",
              "      <td>PRINCETON PPRINCETON UNIVERSITY students garne...</td>\n",
              "      <td>real</td>\n",
              "      <td>No sampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55065</th>\n",
              "      <td>There are not many people who have become mult...</td>\n",
              "      <td>fake</td>\n",
              "      <td>argmax</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55066</th>\n",
              "      <td>West Australian unions are furious the premier...</td>\n",
              "      <td>real</td>\n",
              "      <td>No sampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55067</th>\n",
              "      <td>Kylie Jenner, then and now 07/15/2015 AT 01:50...</td>\n",
              "      <td>fake</td>\n",
              "      <td>argmax</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text label     sampling\n",
              "55063  WASHINGTON, June 1 (Reuters) - U.S. constructi...  fake       argmax\n",
              "55064  PRINCETON PPRINCETON UNIVERSITY students garne...  real  No sampling\n",
              "55065  There are not many people who have become mult...  fake       argmax\n",
              "55066  West Australian unions are furious the premier...  real  No sampling\n",
              "55067  Kylie Jenner, then and now 07/15/2015 AT 01:50...  fake       argmax"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPm7F4gGRQyC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5e50362-4c6e-4dc7-9bc8-e2169a964f77"
      },
      "source": [
        "tokenization = 'gpt2'\n",
        "pretrained_weights = 'gpt2'\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_weights)\n",
        "model = GPT2Model.from_pretrained(pretrained_weights)\n",
        "\n",
        "pad_index = tokenizer.convert_tokens_to_ids('<pad>')\n",
        "embeddings_pretrained = model.get_input_embeddings()\n",
        "embeddings_pretrained"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50257, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cI71U09RWOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text, tokenizer=tokenizer):\n",
        "    return tokenizer.encode(text, max_length=1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu4Y2rB2RdN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmz90W4cRkGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 50000\n",
        "classes={'fake': 0, 'real': 1}\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, \n",
        "                  include_lengths=False,\n",
        "                  batch_first=True, \n",
        "                  tokenize=tokenize, \n",
        "                  pad_first=True,\n",
        "                  lower=False,\n",
        "                  use_vocab=False,\n",
        "                  preprocessing=data.Pipeline(int),\n",
        "                  pad_token=pad_index) \n",
        "\n",
        "LABEL = data.LabelField(dtype=torch.float, \n",
        "                        use_vocab=False, \n",
        "                        sequential=False,\n",
        "                        preprocessing=lambda x: classes[x])\n",
        "\n",
        "\n",
        "dataset = data.TabularDataset('data/sampling_same_{}.csv'.format(SAMPLING), \n",
        "                                format='csv', fields=[('text', TEXT), ('label',LABEL), (None, None)], \n",
        "                                skip_header=True)\n",
        "\n",
        "train, test = dataset.split(0.8, stratified=True)\n",
        "train, valid = train.split(0.8, stratified=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNFS6MKgRqJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDINGS_DIM = embeddings_pretrained.embedding_dim\n",
        "VOCAB_SIZE = embeddings_pretrained.num_embeddings\n",
        "EMB_PRETRAINED = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5qaI0a7Rvip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, \n",
        "                 emb_pretrained, embeddings):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.emb_pretrained = emb_pretrained\n",
        "        self.embedding =  embeddings if self.emb_pretrained else nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.LSTM(input_size=embed_size,\n",
        "                           hidden_size=hidden_size,\n",
        "                           bidirectional=True,\n",
        "                           batch_first=True,\n",
        "                          )\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size * 2 *2, 1)\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "           \n",
        "        _, (hidden, cell) = self.rnn(x)\n",
        "        \n",
        "        hidden = hidden.transpose(0,1)\n",
        "        cell = cell.transpose(0,1)\n",
        "        hidden = hidden.contiguous().view(hidden.size(0),-1)\n",
        "        cell = cell.contiguous().view(cell.size(0),-1)\n",
        "        x = torch.cat([hidden, cell], dim=1).squeeze(1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvhBiyCDRwVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Batch:\n",
        "    \"Object for holding a batch of data during training.\"\n",
        "    def __init__(self, text, label):\n",
        "        self.text = text\n",
        "        self.label = label\n",
        "\n",
        "\n",
        "class BucketIteratorWrapper(DataLoader):\n",
        "    __initialized = False\n",
        "\n",
        "    def __init__(self, iterator: data.Iterator):\n",
        "        self.batch_size = iterator.batch_size\n",
        "        self.num_workers = 1\n",
        "        self.collate_fn = None\n",
        "        self.pin_memory = False\n",
        "        self.drop_last = False\n",
        "        self.timeout = 0\n",
        "        self.worker_init_fn = None\n",
        "        self.sampler = iterator\n",
        "        self.batch_sampler = iterator\n",
        "        self.__initialized = True\n",
        "\n",
        "    def __iter__(self):\n",
        "        return map(\n",
        "            lambda batch: {'features': Batch(batch.text, batch.label).text,\n",
        "                           'targets': Batch(batch.text, batch.label).label.unsqueeze(-1),\n",
        "                          },\n",
        "            self.batch_sampler.__iter__()\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.batch_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJm2nwj9RzlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = {'tokenization/embeddings': tokenization,\n",
        "          'sampling' : SAMPLING,\n",
        "          'dataset_size': df.shape[0],\n",
        "            'batch_size': 128,\n",
        "          'hidden_size' : 256,\n",
        "            'num_epochs': 10}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzKteah-R7ag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d3a1078-4aa6-4f3c-9e88-868f698dcb8d"
      },
      "source": [
        "model = MyModel(VOCAB_SIZE,\n",
        "                embed_size=EMBEDDINGS_DIM,\n",
        "                hidden_size=config['hidden_size'],\n",
        "                emb_pretrained = EMB_PRETRAINED,\n",
        "                embeddings = embeddings_pretrained\n",
        "               )\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train, valid, test),\n",
        "    batch_sizes=(config['batch_size'], config['batch_size'], config['batch_size']),\n",
        "    shuffle=True,\n",
        "    device=device,\n",
        "    sort=False,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    sort_within_batch=False,\n",
        ")\n",
        "\n",
        "train_iterator = BucketIteratorWrapper(train_iterator)\n",
        "valid_iterator = BucketIteratorWrapper(valid_iterator)\n",
        "test_iterator = BucketIteratorWrapper(test_iterator)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), weight_decay=1e-5, lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=2)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "criterion.to(device)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgpB7a5OR9Vt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "dbf75c29-c4d9-433c-c111-cc02ea3f8925"
      },
      "source": [
        "# to check the balance of classes in one batch\n",
        "for el in test_iterator:\n",
        "    print(el['targets'].unique(return_counts=True))\n",
        "    print(el['features'].size())\n",
        "    print(el['targets'].size())\n",
        "    print(model(el['features']).size())\n",
        "    break"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([0., 1.], device='cuda:0'), tensor([63, 65], device='cuda:0'))\n",
            "torch.Size([128, 139])\n",
            "torch.Size([128, 1])\n",
            "torch.Size([128, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29SNO64xR_8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/')\n",
        "logdir = '/content/'\n",
        "RUN_NAME = 'argmax_same'\n",
        "RUN_ID = 'argmax_same'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6a23DFySGvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c76de976-cbba-4cde-8462-102f83183788"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def clean_tqdm():\n",
        "    for instance in list(tqdm._instances): \n",
        "        tqdm._decr_instances(instance)\n",
        "\n",
        "for e in tqdm([1,2,3]):\n",
        "    pass"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12458.33it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWf3Y_yMSJJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "runner = dl.SupervisedRunner(device=device)\n",
        "loaders = OrderedDict(\n",
        "    {'train': train_iterator,\n",
        "    'valid': valid_iterator}\n",
        ")\n",
        "\n",
        "clean_tqdm()\n",
        "runner.train(\n",
        "    model=model, \n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer, \n",
        "    scheduler=scheduler,\n",
        "    loaders=loaders,\n",
        "    logdir=logdir,\n",
        "    num_epochs=config['num_epochs'],\n",
        "    verbose=True,\n",
        "    valid_loader=\"valid\",\n",
        "    callbacks=[AccuracyCallback(num_classes=2,\n",
        "                                activation='Sigmoid',\n",
        "                                threshold=0.5),\n",
        "               EarlyStoppingCallback(patience=4),\n",
        "               WandbLogger(log_on_batch_end=True,\n",
        "                           project=\"dpl\",\n",
        "                           name=RUN_NAME,\n",
        "                           config=config,\n",
        "                           id=RUN_ID\n",
        "                           )],\n",
        "    monitoring_params={\n",
        "                    \"project\": \"dpl\",\n",
        "                    'tags': 'lstm',\n",
        "                    'config': config,\n",
        "    }\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQgaXVAeVuK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b4748ae-eaf1-4bef-9fea-fb631da179bd"
      },
      "source": [
        "results = torch.load('/content/checkpoints/train.3.pth', map_location=device)\n",
        "model.load_state_dict(results['model_state_dict'])"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF0kVD9Lb84J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp \"/content/checkpoints/train.2.pth\" \"/content/drive/My Drive/model_checkpoints/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5RowUTeb_9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_score(preds, y):\n",
        "    preds = torch.round(torch.sigmoid(preds))\n",
        "    preds = (preds == y).float()\n",
        "    accuracy = preds.sum() / len(preds)\n",
        "    return accuracy.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQtvLzvTcB2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, test_iterator):\n",
        "    test_acc = []\n",
        "    with torch.no_grad():\n",
        "        for item in test_iterator:\n",
        "            x = item['features']\n",
        "            y = item['targets'].squeeze(-1)\n",
        "            preds = model(x).squeeze(-1)\n",
        "            test_acc.append(accuracy_score(preds, y))\n",
        "    test_acc = np.mean(test_acc) \n",
        "    return np.mean(test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWgXEYHucF4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11660cb8-61fb-4ed7-e608-c3f9ca82d56c"
      },
      "source": [
        "test_accuracy = test_model(model, test_iterator)\n",
        "print('Test accuracy: {}'.format(np.mean(test_accuracy)))"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9342672413793104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA2C71SgcGti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "bd495f1d-66f8-4d78-a8e6-e81b4eb73d46"
      },
      "source": [
        "wandb.init(id=RUN_ID, config=config)\n",
        "wandb.log({\"Test accc\" : test_accuracy})"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/2ispany3/dpl\" target=\"_blank\">https://app.wandb.ai/2ispany3/dpl</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/2ispany3/dpl/runs/argmax_same\" target=\"_blank\">https://app.wandb.ai/2ispany3/dpl/runs/argmax_same</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Streaming file created twice in same run: /content/wandb/run-20200418_142811-argmax_same/wandb-events.jsonl\n",
            "Streaming file created twice in same run: /content/wandb/run-20200418_142811-argmax_same/wandb-history.jsonl\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ1JoKv0cQL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}