{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-AKZR8DwLSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install alchemy-catalyst\n",
        "!pip install transformers\n",
        "!pip install -U catalyst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGmd135KwYXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N3o_SvM2JtM",
        "colab_type": "code",
        "outputId": "d2873704-7e75-4c98-e1c6-7e551858b61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import wandb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext  import data\n",
        "\n",
        "\n",
        "import catalyst.dl as dl\n",
        "from collections import OrderedDict\n",
        "from catalyst.dl.callbacks  import AccuracyCallback, EarlyStoppingCallback, WandbLogger\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cCxoWqGFLSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO Подобрать кол-во параметров requires_grad\n",
        "# TODO Гиперпараметры\n",
        "# Сравнить с LSTM и еще покопаться в лучшей модели немного"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy13wmKU2UUZ",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6LszcTU2Y-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uncomment if google colab:\n",
        "\n",
        "import os \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/')\n",
        "\n",
        "df = pd.read_csv(\"data/dataset.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORbfywBO2e7U",
        "colab_type": "code",
        "outputId": "18202b04-b34c-45dc-b0a1-f0fb0f0e0827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(483202, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLKKVYpyxJot",
        "colab_type": "code",
        "outputId": "ec68367f-d078-454d-e826-691d34676826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sampling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The police department in Green Mountain Falls,...</td>\n",
              "      <td>real</td>\n",
              "      <td>No sampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DHAKA, Bangladesh—Islamic State militants stor...</td>\n",
              "      <td>fake</td>\n",
              "      <td>nucleus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A few minutes into her visit with plastic surg...</td>\n",
              "      <td>real</td>\n",
              "      <td>No sampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Here is the second item from my \"Albany Inside...</td>\n",
              "      <td>real</td>\n",
              "      <td>No sampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Reversing a long and slow stock decline, share...</td>\n",
              "      <td>real</td>\n",
              "      <td>No sampling</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label     sampling\n",
              "0  The police department in Green Mountain Falls,...  real  No sampling\n",
              "1  DHAKA, Bangladesh—Islamic State militants stor...  fake      nucleus\n",
              "2  A few minutes into her visit with plastic surg...  real  No sampling\n",
              "3  Here is the second item from my \"Albany Inside...  real  No sampling\n",
              "4  Reversing a long and slow stock decline, share...  real  No sampling"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBd8G7RWfDaM",
        "colab_type": "text"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLfcQZOv2tpF",
        "colab_type": "code",
        "outputId": "0f3215a3-b4aa-47a8-c13b-c208bc6a92a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pretrained_weights = 'bert-base-uncased'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\n",
        "bert = BertForSequenceClassification.from_pretrained(pretrained_weights)\n",
        "\n",
        "pad_index = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
        "embeddings_pretrained = bert.get_input_embeddings()\n",
        "embeddings_pretrained"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(30522, 768, padding_idx=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko8wvbXZ6zSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDiCVgZv68j1",
        "colab_type": "code",
        "outputId": "7efdf5c4-6e79-4589-d0ba-73b1c3808dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "def tokenize(text, tokenizer=tokenizer):\n",
        "    return tokenizer.encode(text, max_length=512)\n",
        "\n",
        "MAX_VOCAB_SIZE = 50000\n",
        "classes={'fake': 0, 'real': 1}\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, \n",
        "                  include_lengths=False,\n",
        "                  batch_first=True, \n",
        "                  tokenize=tokenize, \n",
        "                  pad_first=True,\n",
        "                  lower=False,\n",
        "                  use_vocab=False,\n",
        "                  preprocessing=data.Pipeline(int),\n",
        "                  pad_token=pad_index) \n",
        "\n",
        "LABEL = data.LabelField(dtype=torch.float, \n",
        "                        use_vocab=False, \n",
        "                        sequential=False,\n",
        "                        preprocessing=lambda x: classes[x])\n",
        "\n",
        "\n",
        "dataset = data.TabularDataset('data/dataset.csv', \n",
        "                                format='csv', fields=[('text', TEXT), ('label',LABEL), (None, None)], \n",
        "                                skip_header=True)\n",
        "\n",
        "train, test = dataset.split(0.8, stratified=True)\n",
        "train, valid = train.split(0.8, stratified=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/10 * Epoch (train):   0% 0/2417 [36:47<?, ?it/s]\n",
            "1/10 * Epoch (train):   0% 0/2417 [23:18<?, ?it/s]\n",
            "1/10 * Epoch (train):   0% 0/2417 [17:48<?, ?it/s]\n",
            "1/10 * Epoch (train):   0% 0/2417 [11:34<?, ?it/s]\n",
            "1/10 * Epoch (train):   0% 0/2417 [08:46<?, ?it/s]\n",
            "1/10 * Epoch (train):   0% 0/2417 [07:28<?, ?it/s]\n",
            "1/10 * Epoch (train):   0% 0/2417 [04:38<?, ?it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B-Ssi6Wxz0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Batch:\n",
        "    \"Object for holding a batch of data during training.\"\n",
        "    def __init__(self, text, label):\n",
        "        self.text = text\n",
        "        self.label = label\n",
        "\n",
        "\n",
        "class BucketIteratorWrapper(DataLoader):\n",
        "    __initialized = False\n",
        "\n",
        "    def __init__(self, iterator: data.Iterator):\n",
        "        self.batch_size = iterator.batch_size\n",
        "        self.num_workers = 1\n",
        "        self.collate_fn = None\n",
        "        self.pin_memory = False\n",
        "        self.drop_last = False\n",
        "        self.timeout = 0\n",
        "        self.worker_init_fn = None\n",
        "        self.sampler = iterator\n",
        "        self.batch_sampler = iterator\n",
        "        self.__initialized = True\n",
        "\n",
        "    def __iter__(self):\n",
        "        return map(\n",
        "            lambda batch: {'features': Batch(batch.text, batch.label).text,\n",
        "                           'targets': Batch(batch.text, batch.label).label.unsqueeze(-1),\n",
        "                          },\n",
        "            self.batch_sampler.__iter__()\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.batch_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgyqhVrZx4OC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = {'tokenization/embeddings': 'bert',\n",
        "            'batch_size': 128,\n",
        "          'hidden_size' : 256,\n",
        "            'num_epochs': 10}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KzPLnpqy1Az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.bert = bert\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.size())\n",
        "        x = bert(x)[0]\n",
        "        # print(len(x))\n",
        "        # print(x[0].size())\n",
        "        # # loss, logits = outputs[:2]\n",
        "        # _, preds = torch.max(F.softmax(x, dim=1),1)\n",
        "        x, _ = torch.max(F.softmax(x, dim=1),1)\n",
        "        # print(x.size())\n",
        "        # print(x)\n",
        "        return x.unsqueeze(-1)\n",
        "\n",
        "# class MyCriterion(nn.Module):\n",
        "#     def __init__(self, bert):\n",
        "#         super(MyCriterion, self).__init__()\n",
        "#         self.pad_idx = pad_idx\n",
        "#         self.criterion = nn.CrossEntropyLoss(reduction='sum', ignore_index=pad_idx)\n",
        "        \n",
        "#     def forward(self, x, target):\n",
        "#         x = x.contiguous().permute(0,2,1)\n",
        "#         ntokens = (target != self.pad_idx).data.sum()\n",
        "        \n",
        "#         return self.criterion(x, target) / ntokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqdIPdwZ0uIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MyModel(bert=bert)\n",
        "model.to(device)\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train, valid, test),\n",
        "    batch_sizes=(config['batch_size'], config['batch_size'], config['batch_size']),\n",
        "    shuffle=True,\n",
        "    device=device,\n",
        "    sort=False,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    sort_within_batch=False,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3PCQ8z61oJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for p in model.bert.bert.encoder.parameters(): \n",
        "    p.requires_grad = False \n",
        "\n",
        "for p in model.bert.bert.pooler.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "for p in model.bert.bert.embeddings.parameters(): \n",
        "    p.requires_grad = False "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSLW70C008Dt",
        "colab_type": "code",
        "outputId": "62c1d03c-d095-4567-9643-d2cdffd31f48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "for el in train_iterator:\n",
        "    with torch.no_grad():\n",
        "        print(el.label.size())\n",
        "        print(model(el.text).size())\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK1bURO79gB0",
        "colab_type": "code",
        "outputId": "b103a84b-ac8c-4b36-8c36-59a5e5736f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = MyModel(bert=bert)\n",
        "model.to(device)\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train, valid, test),\n",
        "    batch_sizes=(config['batch_size'], config['batch_size'], config['batch_size']),\n",
        "    shuffle=True,\n",
        "    device=device,\n",
        "    sort=False,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    sort_within_batch=False,\n",
        ")\n",
        "\n",
        "train_iterator = BucketIteratorWrapper(train_iterator)\n",
        "valid_iterator = BucketIteratorWrapper(valid_iterator)\n",
        "test_iterator = BucketIteratorWrapper(test_iterator)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=2)\n",
        "criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHEt6BcVBXYK",
        "colab_type": "code",
        "outputId": "eeee81db-a2dc-4143-ea37-6b1437902e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "for el in test_iterator:\n",
        "    print(el['targets'].unique(return_counts=True))\n",
        "    print(el['features'].size())\n",
        "    print(el['targets'].size())\n",
        "    print(model(el['features']).size())\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([0., 1.], device='cuda:0'), tensor([66, 62], device='cuda:0'))\n",
            "torch.Size([128, 115])\n",
            "torch.Size([128, 1])\n",
            "torch.Size([128, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki_52I0tPOAr",
        "colab_type": "code",
        "outputId": "f449a535-dde2-4a62-d6ba-4ae406e5bd1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my9-_OzAQWyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for p in model.bert.bert.encoder.parameters(): \n",
        "    p.requires_grad = False \n",
        "\n",
        "for p in model.bert.bert.pooler.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "for p in model.bert.bert.embeddings.parameters(): \n",
        "    p.requires_grad = False \n",
        "\n",
        "# for p in model.bert.encoder.layer[-1].parameters():\n",
        "#     p.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_JojorsPkMs",
        "colab_type": "code",
        "outputId": "4339ea7f-7f27-4f82-fedc-29ca6eb43fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vam7QzxPFGeP",
        "colab_type": "text"
      },
      "source": [
        "# Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-bZiWwu5uWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/')\n",
        "logdir = '/content/'\n",
        "RUN_NAME = 'bert_test'\n",
        "RUN_ID = 'sbrtсxczybs'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXd9pwiS5ylW",
        "colab_type": "code",
        "outputId": "97d782ab-959b-4e68-cfdf-3bf9a0341f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "def clean_tqdm():\n",
        "    for instance in list(tqdm._instances): \n",
        "        tqdm._decr_instances(instance)\n",
        "\n",
        "for e in tqdm([1,2,3]):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 3/3 [00:00<00:00, 15069.36it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahZ0joQL502X",
        "colab_type": "code",
        "outputId": "1677a3fc-01e1-4243-f69b-296474900174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "runner = dl.SupervisedRunner(device=device)\n",
        "loaders = OrderedDict(\n",
        "    {'train': train_iterator,\n",
        "    'valid': valid_iterator}\n",
        ")\n",
        "\n",
        "clean_tqdm()\n",
        "runner.train(\n",
        "    model=model, \n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer, \n",
        "    scheduler=scheduler,\n",
        "    loaders=loaders,\n",
        "    logdir=logdir,\n",
        "    num_epochs=config['num_epochs'],\n",
        "    verbose=True,\n",
        "    valid_loader=\"valid\",\n",
        "    callbacks=[AccuracyCallback(num_classes=2,\n",
        "                                activation='Sigmoid',\n",
        "                                threshold=0.5),\n",
        "               EarlyStoppingCallback(patience=4),\n",
        "               WandbLogger(log_on_batch_end=True,\n",
        "                           project=\"dpl\",\n",
        "                           name=RUN_NAME,\n",
        "                           config=config,\n",
        "                           id=RUN_ID\n",
        "                           )],\n",
        "    monitoring_params={\n",
        "                    \"project\": \"dpl\",\n",
        "                    'tags': 'lstm',\n",
        "                    'config': config,\n",
        "    }\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/2ispany3/dpl\" target=\"_blank\">https://app.wandb.ai/2ispany3/dpl</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/2ispany3/dpl/runs/sbrt%D1%81xczybs\" target=\"_blank\">https://app.wandb.ai/2ispany3/dpl/runs/sbrt%D1%81xczybs</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r1/10 * Epoch (train):   0% 0/2417 [00:00<?, ?it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Streaming file created twice in same run: /content/wandb/run-20200417_213440-sbrtсxczybs/wandb-events.jsonl\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early exiting\n",
            "1/10 * Epoch (train):  11% 263/2417 [02:18<18:59,  1.89it/s, accuracy01=0.469, loss=0.745]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldzDAeGYEwq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = torch.load('/content/checkpoints/train.2.pth', map_location=device)\n",
        "model.load_state_dict(results['model_state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H81B-necExZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/checkpoints/train.2.pth\" \"/content/drive/My Drive/model_checkpoints/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibET8LlfEzvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_score(preds, y):\n",
        "    preds = torch.round(torch.sigmoid(preds))\n",
        "    preds = (preds == y).float()\n",
        "    accuracy = preds.sum() / len(preds)\n",
        "    return accuracy.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ3ae66FE1cT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, test_iterator):\n",
        "    test_acc = []\n",
        "    with torch.no_grad():\n",
        "        for item in test_iterator:\n",
        "            x = item['features']\n",
        "            y = item['targets'].squeeze(-1)\n",
        "            preds = model(x).squeeze(-1)\n",
        "            test_acc.append(accuracy_score(preds, y))\n",
        "    test_acc = np.mean(test_acc) \n",
        "    return np.mean(test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_biOZvKE3dF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy = test_model(model, test_iterator)\n",
        "print('Test accuracy: {}'.format(np.mean(test_accuracy)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOOQLMH2E5uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wandb.init(id=RUN_ID, config=config)\n",
        "wandb.log({\"Test accc\" : test_accuracy})"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}