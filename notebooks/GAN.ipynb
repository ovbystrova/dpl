{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNZ2myAWLAfTyDLFdxgHQqx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ovbystrova/dpl/blob/master/notebooks/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ96ND8WdXbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/williamSYSU/TextGAN-PyTorch\n",
        "# https://github.com/DSleeps/Text-GAN\n",
        "# https://github.com/rtst777/TextGAN\n",
        "# https://github.com/MuratArda-coder/GAN-Text-Generation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCc9KHQIujh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO Gumbel_softmax\n",
        "# TODO train/test loop\n",
        "# TODO Перенести модели в models\n",
        "# А всю train/test процедуру в modules мб"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5tBWZ_yPDmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "4e8a41d6-001c-4bc6-e303-c1270232c0c2"
      },
      "source": [
        "!git clone https://github.com/ovbystrova/dpl.git\n",
        "import os\n",
        "os.chdir('/content/dpl')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dpl'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 189 (delta 0), reused 0 (delta 0), pack-reused 185\u001b[K\n",
            "Receiving objects: 100% (189/189), 228.87 MiB | 33.56 MiB/s, done.\n",
            "Resolving deltas: 100% (101/101), done.\n",
            "Checking out files: 100% (28/28), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiBmwcdxa6cG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install tokenizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOC28VNSbBac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc2f8dbb-9ac2-4e85-e0a2-6e6b82a071a4"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchtext import data\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAjOx2i2P_RL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from modules.sntpiece_tokenization import make_tokenizer, clean_data, special_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpLoNhVR0DB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LM_PATH = '/content/language_model'\n",
        "EMB_PATH  = '/content/embeddings_y.pt'\n",
        "BATCH_SIZE = 64\n",
        "SEQ_LENGTH = 40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olkt2eArdpTh",
        "colab_type": "text"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G6F8nWXQPy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip\n",
        "!unzip 'wikitext-2-v1.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JMoqW8_QFBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c1b644f-dfad-4fe4-988b-389d9259b989"
      },
      "source": [
        "tokenizer = make_tokenizer()\n",
        "tokenizer"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tokenizer(vocabulary_size=30000, model=SentencePieceBPE, unk_token=<unk>, replacement=▁, add_prefix_space=True, dropout=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr0uyM1EQesO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text, tokenizer=tokenizer):\n",
        "    text = clean_data(text)\n",
        "    text = special_tokens(text)\n",
        "    return tokenizer.encode(text).tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1hVlz3i-Zmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "TEXT = data.Field(sequential=True, \n",
        "                  include_lengths=False, \n",
        "                  batch_first=True, \n",
        "                  tokenize=tokenize,\n",
        "                  lower=True, \n",
        "                  pad_first=True)\n",
        "\n",
        "train, valid, test = WikiText2.splits(TEXT)\n",
        "\n",
        "TEXT.build_vocab(train, valid, unk_init = torch.Tensor.normal_, vectors='glove.6B.200d')\n",
        "vocab = TEXT.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFv6nDRgz6le",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e999221d-7533-4601-e53d-bbc204a8334f"
      },
      "source": [
        "print('Vocab size:', len(TEXT.vocab.itos))\n",
        "TEXT.vocab.itos[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 22734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '▁', '▁the', '<eos>', '<start>', '▁,', '▁of', '▁and', '▁in']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPlJ8_RE-gaO",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGQjFrxJldMp",
        "colab_type": "text"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE52JeiG-hmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(input_size=embed_dim,\n",
        "                           hidden_size=hidden_size,\n",
        "                           bidirectional=True,\n",
        "                           batch_first=True,\n",
        "                          )\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size * 2, vocab_size)\n",
        "        self.fc2 = nn.Linear(vocab_size, embed_dim)\n",
        "        \n",
        "        self.init_weights()\n",
        "        \n",
        "    def init_weights(self):\n",
        "        nn.init.uniform_(self.embedding.weight)\n",
        "        nn.init.xavier_uniform_(self.fc.weight)\n",
        "        nn.init.zeros_(self.fc.bias)\n",
        "        \n",
        "    def forward(self, batch):\n",
        "        \n",
        "        x = batch.text.T if hasattr(batch, 'text') else batch #\n",
        "        \n",
        "        x = self.embedding(x)           \n",
        "        x, _ = self.rnn(x)  # (bs,sq,hs)\n",
        "        x = self.fc(x)  # (bs,sq,vocab_size)\n",
        "        # x = F.softmax(x, dim=-1)  # (bs,sq,vocab_size)\n",
        "        # x = self.fc2(x)  # (bs,sq,embed_dim)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLKXqRPh-mmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MyModel(vocab_size=len(TEXT.vocab.itos),\n",
        "                embed_dim=200,\n",
        "                hidden_size=128,\n",
        "               )\n",
        "model.to(device)\n",
        "# model.embedding.weight.data.copy_(TEXT.vocab.vectors);\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=1)\n",
        "cosine = nn.CosineSimilarity(dim=-1)\n",
        "mse = nn.MSELoss()\n",
        "embed_y = nn.Embedding(len(TEXT.vocab.itos), 200).to(device)  \n",
        "embed_y.weight.data.copy_(torch.load(EMB_PATH));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cGMnhE92s9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "9a05608e-5648-466c-d986-5f07f6abd95e"
      },
      "source": [
        "embed_y.weight.data, model.embedding.weight.data"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 3.0568,  0.5324,  0.5345,  ...,  0.9580, -2.3471, -0.8556],\n",
              "         [ 0.7384,  2.5978,  0.7651,  ..., -1.1332, -0.6784,  0.7710],\n",
              "         [-1.2101,  0.7566, -0.1192,  ..., -0.0474,  0.1571, -0.9504],\n",
              "         ...,\n",
              "         [ 0.9455,  1.1042, -1.0881,  ..., -0.7559, -1.0561, -1.2703],\n",
              "         [ 0.3659,  0.6635,  0.2631,  ...,  0.1843,  0.2070, -0.4724],\n",
              "         [-0.3153, -0.4700,  0.1212,  ...,  1.4813,  0.4461,  0.7010]],\n",
              "        device='cuda:0'),\n",
              " tensor([[0.9057, 0.7520, 0.7495,  ..., 0.6955, 0.7204, 0.5740],\n",
              "         [0.5404, 0.5462, 0.7705,  ..., 0.4520, 0.8386, 0.5561],\n",
              "         [0.4474, 0.6563, 0.7178,  ..., 0.1666, 0.2965, 0.6375],\n",
              "         ...,\n",
              "         [0.9409, 0.5975, 0.5933,  ..., 0.7461, 0.0658, 0.6108],\n",
              "         [0.1584, 0.4989, 0.3269,  ..., 0.7748, 0.3414, 0.0637],\n",
              "         [0.5473, 0.2768, 0.6072,  ..., 0.7621, 0.7178, 0.3665]],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbKza8IF2hdA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59546727-3ca9-45dd-8d97-39db8db9cffe"
      },
      "source": [
        "train_iterator_g, valid_iterator_g, test_iterator_g = data.BPTTIterator.splits(\n",
        "    (train, valid, test),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    bptt_len=SEQ_LENGTH,\n",
        "    device=device,\n",
        "    repeat=False, \n",
        "    shuffle=True)\n",
        "\n",
        "b = next(iter(train_iterator_g)); vars(b).keys()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['batch_size', 'dataset', 'fields', 'text', 'target'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsLIZ1UJVmg9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "6b5e81ef-8f4b-4b99-cb46-0a44596a25b9"
      },
      "source": [
        "for el in train_iterator_g:\n",
        "    x = el.text\n",
        "    y = el.target.T\n",
        "    print(x.size(), y.size())\n",
        "    pred = model(el)\n",
        "    y_emb = embed_y(y)\n",
        "    \n",
        "    loss_mse = mse(pred, y_emb)\n",
        "    print('mse', loss_mse)\n",
        "    loss_cosine = cosine(pred, y_emb)\n",
        "    print('cosine', loss_cosine.size())\n",
        "\n",
        "    mean_cosine  = torch.mean(loss_cosine, dim=-1)\n",
        "    mean_mean_cosine = torch.mean(mean_cosine)\n",
        "    print(mean_cosine.size(), mean_mean_cosine.size())\n",
        "    print(1-mean_mean_cosine)\n",
        "    break"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([40, 64]) torch.Size([64, 40])\n",
            "mse tensor(0.9678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "cosine torch.Size([64, 40])\n",
            "torch.Size([64]) torch.Size([])\n",
            "tensor(1.0025, device='cuda:0', grad_fn=<RsubBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POdo-iY-lgUc",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_GOyR0zl_D2",
        "colab_type": "text"
      },
      "source": [
        "### from RelGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXn2Q9iioerp",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/williamSYSU/TextGAN-PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuSWybRHliKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNDiscriminator(nn.Module):\n",
        "    def __init__(self, embed_dim, vocab_size, filter_sizes, num_filters, padding_idx, gpu=False,\n",
        "                 dropout=0.2):\n",
        "        super(CNNDiscriminator, self).__init__()\n",
        "        self.embedding_dim = embed_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.padding_idx = padding_idx\n",
        "        self.feature_dim = sum(num_filters)\n",
        "        self.gpu = gpu\n",
        "\n",
        "        # self.embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(1, n, (f, embed_dim)) for (n, f) in zip(num_filters, filter_sizes)\n",
        "        ])\n",
        "        self.highway = nn.Linear(self.feature_dim, self.feature_dim)\n",
        "        self.feature2out = nn.Linear(self.feature_dim, 2)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.init_params()\n",
        "\n",
        "    def forward(self, inp):\n",
        "        \"\"\"\n",
        "        Get final predictions of discriminator\n",
        "        :param inp: batch_size * seq_len * embed_dim\n",
        "        :return: pred: batch_size * 2\n",
        "        \"\"\"\n",
        "        feature = self.get_feature(inp)\n",
        "        pred = self.feature2out(self.dropout(feature))\n",
        "\n",
        "        return pred\n",
        "\n",
        "    def get_feature(self, inp):\n",
        "        \"\"\"\n",
        "        Get feature vector of given sentences\n",
        "        :param inp: batch_size * max_seq_len\n",
        "        :return: batch_size * feature_dim\n",
        "        \"\"\"\n",
        "        emb = self.embeddings(inp).unsqueeze(1)  # batch_size * 1 * max_seq_len * embed_dim\n",
        "        convs = [F.relu(conv(emb)).squeeze(3) for conv in self.convs]  # [batch_size * num_filter * length]\n",
        "        pools = [F.max_pool1d(conv, conv.size(2)).squeeze(2) for conv in convs]  # [batch_size * num_filter]\n",
        "        pred = torch.cat(pools, 1)  # tensor: batch_size * feature_dim\n",
        "        highway = self.highway(pred)\n",
        "        pred = torch.sigmoid(highway) * F.relu(highway) + (1. - torch.sigmoid(highway)) * pred  # highway\n",
        "\n",
        "        return pred\n",
        "\n",
        "    def init_params(self):\n",
        "        for param in self.parameters():\n",
        "            if param.requires_grad and len(param.shape) > 0:\n",
        "                stddev = 1 / math.sqrt(param.shape[0])\n",
        "                if cfg.dis_init == 'uniform':\n",
        "                    torch.nn.init.uniform_(param, a=-0.05, b=0.05)\n",
        "                elif cfg.dis_init == 'normal':\n",
        "                    torch.nn.init.normal_(param, std=stddev)\n",
        "                elif cfg.dis_init == 'truncated_normal':\n",
        "                    truncated_normal_(param, std=stddev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAevui7Fne3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RelGAN_D(CNNDiscriminator):\n",
        "    def __init__(self, embed_dim, max_seq_len, num_rep, vocab_size, padding_idx, gpu=False, dropout=0.25):\n",
        "        super(RelGAN_D, self).__init__(embed_dim, vocab_size, dis_filter_sizes, dis_num_filters, padding_idx,\n",
        "                                       gpu, dropout)\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.feature_dim = sum(dis_num_filters)\n",
        "        self.emb_dim_single = int(embed_dim / num_rep)\n",
        "\n",
        "        self.embeddings = nn.Linear(vocab_size, embed_dim, bias=False)\n",
        "        # self.embeddings = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(1, n, (f, self.emb_dim_single), stride=(1, self.emb_dim_single)) for (n, f) in\n",
        "            zip(dis_num_filters, dis_filter_sizes)\n",
        "        ])\n",
        "\n",
        "        self.highway = nn.Linear(self.feature_dim, self.feature_dim)\n",
        "        self.feature2out = nn.Linear(self.feature_dim, 100)\n",
        "        self.out2logits = nn.Linear(100, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.init_params()\n",
        "\n",
        "    def forward(self, inp):\n",
        "        \"\"\"\n",
        "        Get logits of discriminator\n",
        "        :param inp: batch_size * seq_len * embed_dim\n",
        "        :return logits: [batch_size * num_rep] (1-D tensor)\n",
        "        \"\"\"\n",
        "\n",
        "        emb = self.embeddings(inp).unsqueeze(1) if inp.size()[-1]==self.vocab_size else inp.unsqueeze(1)\n",
        "        # emb = self.embeddings(inp).unsqueeze(1)  # batch_size * 1 * max_seq_len * embed_dim\n",
        "        cons = [F.relu(conv(emb)) for conv in self.convs]  # [batch_size * num_filter * (seq_len-k_h+1) * num_rep]\n",
        "        pools = [F.max_pool2d(con, (con.size(2), 1)).squeeze(2) for con in cons]  # [batch_size * num_filter * num_rep]\n",
        "        pred = torch.cat(pools, 1)\n",
        "        pred = pred.permute(0, 2, 1).contiguous().view(-1, self.feature_dim)  # (batch_size * num_rep) * feature_dim\n",
        "        highway = self.highway(pred)\n",
        "        pred = torch.sigmoid(highway) * F.relu(highway) + (1. - torch.sigmoid(highway)) * pred  # highway\n",
        "\n",
        "        pred = self.feature2out(self.dropout(pred))\n",
        "        logits = self.out2logits(pred).squeeze(1)  # [batch_size * num_rep]\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CROOsUx2o0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterators for dicriminator\n",
        "train_iterator_d, valid_iterator_d, test_iterator_d = data.BPTTIterator.splits(\n",
        "    (train, valid, test),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    bptt_len=SEQ_LENGTH,\n",
        "    device=device,\n",
        "    repeat=False, \n",
        "    shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb_NZ_b_rbpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from collections import namedtuple\n",
        "dis_filter_sizes = [2, 3, 4, 5]\n",
        "dis_num_filters = [300, 300, 300, 300]\n",
        "cfg = namedtuple('cfg', ['dis_init'])\n",
        "cfg.dis_init='uniform'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEnmvdsTpymT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fe7545a-c224-4350-8bb8-93f92912463d"
      },
      "source": [
        "discriminator = RelGAN_D(embed_dim=200,\n",
        "                         max_seq_len=SEQ_LENGTH+10,\n",
        "                         num_rep=1,\n",
        "                         vocab_size=len(TEXT.vocab),\n",
        "                         padding_idx=TEXT.vocab.stoi['<pad>'],\n",
        "                         gpu=True)\n",
        "discriminator.to(device)\n",
        "\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "bce.to(device)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB4qncYoVzzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "0c9816e1-f506-4ef8-c1a0-b632bd266893"
      },
      "source": [
        "for el in train_iterator_d:\n",
        "    with torch.no_grad():\n",
        "        x = embed_y(el.text.T)\n",
        "        print(x.size(), len(x.size()))\n",
        "        print(x.type())\n",
        "        y = torch.ones((x.size()[0])).to(device)\n",
        "        print(y.size(), y)\n",
        "\n",
        "        preds = discriminator(x)\n",
        "        print(preds.size())\n",
        "        bce_crit = bce(preds, y)\n",
        "        print(bce_crit)\n",
        "        print(preds)\n",
        "        # print(x.size())\n",
        "        # print(y.size())\n",
        "        # out = model(x)\n",
        "        # print(y.unique(return_counts=True))\n",
        "        # print(x.size())\n",
        "        # print(y.size())\n",
        "        # print(out.size())\n",
        "        # print(criterion(out, y.long()))\n",
        "        print('===And now the generator===')\n",
        "        for elem in train_iterator_g:\n",
        "            with torch.no_grad():\n",
        "                x_g = elem.text\n",
        "                y_g = elem.target.T\n",
        "                print(x_g.size(), y_g.size())\n",
        "                pred = model(el)\n",
        "                y_emb = embed_y(y_g)\n",
        "\n",
        "                g_preds = discriminator(pred)\n",
        "                y_gen = torch.zeros((x.size()[0])).to(device)\n",
        "                print(preds.size())\n",
        "                bce_g = bce(preds, y_gen)\n",
        "                print(bce_g)\n",
        "                print(preds)\n",
        "                break\n",
        "        break"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 40, 200]) 3\n",
            "torch.cuda.FloatTensor\n",
            "torch.Size([64]) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "torch.Size([64])\n",
            "tensor(0.5397, device='cuda:0')\n",
            "tensor([ 4.8655e-01, -1.7155e-01,  7.0880e-01,  7.8546e-01,  5.3187e-01,\n",
            "        -1.3842e-01,  5.4085e-01,  8.0878e-01,  1.7995e-01,  4.6545e-01,\n",
            "         1.7111e-01,  1.9617e-01,  6.9969e-01,  4.6513e-01,  9.4334e-01,\n",
            "         5.4059e-01,  1.6986e-01,  7.1093e-01,  5.4225e-01,  6.6428e-01,\n",
            "         7.6511e-02,  6.3933e-01,  1.9427e-01,  2.8120e-01,  2.9529e-01,\n",
            "         1.1103e-02, -1.4094e-01,  2.3796e-01,  5.8419e-01,  3.0412e-01,\n",
            "         1.5034e-01, -6.3595e-02,  2.1817e-01,  2.9322e-01,  6.4291e-01,\n",
            "         5.5429e-01,  4.8597e-01,  7.1266e-01,  2.3863e-01,  9.1935e-01,\n",
            "         2.9309e-01,  5.1306e-01,  2.3139e-01, -3.5783e-04,  6.5488e-01,\n",
            "         7.6903e-01,  3.4558e-01,  2.2138e-01,  1.7337e-01,  6.1480e-02,\n",
            "         2.7196e-01,  1.9724e-01,  2.6998e-01,  1.2838e-01,  5.4355e-01,\n",
            "         4.3832e-01,  4.2482e-01, -1.3152e-01,  1.1242e-01,  3.6841e-01,\n",
            "         2.9026e-01,  4.7802e-01, -9.2358e-02,  3.0004e-01], device='cuda:0')\n",
            "===And now the generator===\n",
            "torch.Size([40, 64]) torch.Size([64, 40])\n",
            "torch.Size([64])\n",
            "tensor(0.8959, device='cuda:0')\n",
            "tensor([ 4.8655e-01, -1.7155e-01,  7.0880e-01,  7.8546e-01,  5.3187e-01,\n",
            "        -1.3842e-01,  5.4085e-01,  8.0878e-01,  1.7995e-01,  4.6545e-01,\n",
            "         1.7111e-01,  1.9617e-01,  6.9969e-01,  4.6513e-01,  9.4334e-01,\n",
            "         5.4059e-01,  1.6986e-01,  7.1093e-01,  5.4225e-01,  6.6428e-01,\n",
            "         7.6511e-02,  6.3933e-01,  1.9427e-01,  2.8120e-01,  2.9529e-01,\n",
            "         1.1103e-02, -1.4094e-01,  2.3796e-01,  5.8419e-01,  3.0412e-01,\n",
            "         1.5034e-01, -6.3595e-02,  2.1817e-01,  2.9322e-01,  6.4291e-01,\n",
            "         5.5429e-01,  4.8597e-01,  7.1266e-01,  2.3863e-01,  9.1935e-01,\n",
            "         2.9309e-01,  5.1306e-01,  2.3139e-01, -3.5783e-04,  6.5488e-01,\n",
            "         7.6903e-01,  3.4558e-01,  2.2138e-01,  1.7337e-01,  6.1480e-02,\n",
            "         2.7196e-01,  1.9724e-01,  2.6998e-01,  1.2838e-01,  5.4355e-01,\n",
            "         4.3832e-01,  4.2482e-01, -1.3152e-01,  1.1242e-01,  3.6841e-01,\n",
            "         2.9026e-01,  4.7802e-01, -9.2358e-02,  3.0004e-01], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvTXia0w0SJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Как прокидывать генерацию?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXUuHH5umDOH",
        "colab_type": "text"
      },
      "source": [
        "### from LeakGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXKFAR2cmF-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vntAbVN1mEvE",
        "colab_type": "text"
      },
      "source": [
        "### from me"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57nn5FMnmJB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDiCyc2qljb2",
        "colab_type": "text"
      },
      "source": [
        "## test if everything is ok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPbG8lsy2AKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _test_epoch(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    losses = []\n",
        "    cosines = []\n",
        "\n",
        "    n_batches = len(iterator)\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            pred = model(batch)\n",
        "            y_emb = embed_y(batch.target.T)\n",
        "            loss = mse(pred, y_emb)\n",
        "            losses.append(loss.item())\n",
        "            epoch_loss += loss.data.item()\n",
        "\n",
        "            cosine_batch = (1- torch.mean(torch.mean(cosine(pred, y_emb)), dim=-1)).item()\n",
        "            cosines.append(cosine_batch)\n",
        "\n",
        "    return epoch_loss / n_batches, losses, cosines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybvG-jIF2F_0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2260ad00-14b7-4d6a-ca1b-b07affd8408d"
      },
      "source": [
        "test_loss, epoch_test, epoch_tcosines = _test_epoch(model, test_iterator, mse)\n",
        "test_loss"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9693561161557833"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CenBdFoqfFl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4929e15e-35cc-4f79-a88c-77dfa30e2669"
      },
      "source": [
        "# load the weights of pretrained generator (notebooks/Language_Model_exp.ipynb)\n",
        "model.load_state_dict(torch.load(LM_PATH))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp-WCdtE19la",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, epoch_test, epoch_tcosines = _test_epoch(model, test_iterator_g, mse)\n",
        "test_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT55LdfB1Amd",
        "colab_type": "text"
      },
      "source": [
        "# GAN stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M34FeHXO1Cxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FpOZGRQd1UV",
        "colab_type": "text"
      },
      "source": [
        "# Train stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtpmCxcid30y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}