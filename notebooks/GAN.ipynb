{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQ96ND8WdXbH"
   },
   "outputs": [],
   "source": [
    "# https://github.com/williamSYSU/TextGAN-PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RiBmwcdxa6cG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.7.0-cp37-cp37m-win_amd64.whl (1.1 MB)\n",
      "Installing collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.7.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\diploma\\\\github\\\\dpl'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# os.getcwd()\n",
    "# # os.chdir('..')\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.sntpiece_tokenization import make_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = make_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(vocabulary_size=30000, model=SentencePieceBPE, unk_token=<unk>, replacement=▁, add_prefix_space=True, dropout=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EOC28VNSbBac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ormdOBIMbpQm"
   },
   "outputs": [],
   "source": [
    "class CNNDiscriminator(nn.Module):\n",
    "    def __init__(self, embed_dim, vocab_size, filter_sizes, num_filters, padding_idx, gpu=False,\n",
    "                 dropout=0.2):\n",
    "        super(CNNDiscriminator, self).__init__()\n",
    "        self.embedding_dim = embed_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.padding_idx = padding_idx\n",
    "        self.feature_dim = sum(num_filters)\n",
    "        self.gpu = gpu\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, n, (f, embed_dim)) for (n, f) in zip(num_filters, filter_sizes)\n",
    "        ])\n",
    "        self.highway = nn.Linear(self.feature_dim, self.feature_dim)\n",
    "        self.feature2out = nn.Linear(self.feature_dim, 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.init_params()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        \"\"\"\n",
    "        Get final predictions of discriminator\n",
    "        :param inp: batch_size * seq_len\n",
    "        :return: pred: batch_size * 2\n",
    "        \"\"\"\n",
    "        feature = self.get_feature(inp)\n",
    "        pred = self.feature2out(self.dropout(feature))\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def get_feature(self, inp):\n",
    "        \"\"\"\n",
    "        Get feature vector of given sentences\n",
    "        :param inp: batch_size * max_seq_len\n",
    "        :return: batch_size * feature_dim\n",
    "        \"\"\"\n",
    "        emb = self.embeddings(inp).unsqueeze(1)  # batch_size * 1 * max_seq_len * embed_dim\n",
    "        convs = [F.relu(conv(emb)).squeeze(3) for conv in self.convs]  # [batch_size * num_filter * length]\n",
    "        pools = [F.max_pool1d(conv, conv.size(2)).squeeze(2) for conv in convs]  # [batch_size * num_filter]\n",
    "        pred = torch.cat(pools, 1)  # tensor: batch_size * feature_dim\n",
    "        highway = self.highway(pred)\n",
    "        pred = torch.sigmoid(highway) * F.relu(highway) + (1. - torch.sigmoid(highway)) * pred  # highway\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def init_params(self):\n",
    "        for param in self.parameters():\n",
    "            if param.requires_grad and len(param.shape) > 0:\n",
    "                stddev = 1 / math.sqrt(param.shape[0])\n",
    "                if cfg.dis_init == 'uniform':\n",
    "                    torch.nn.init.uniform_(param, a=-0.05, b=0.05)\n",
    "                elif cfg.dis_init == 'normal':\n",
    "                    torch.nn.init.normal_(param, std=stddev)\n",
    "                elif cfg.dis_init == 'truncated_normal':\n",
    "                    truncated_normal_(param, std=stddev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAQj2ePVbymv"
   },
   "outputs": [],
   "source": [
    "class RelGAN_D(CNNDiscriminator):\n",
    "    def __init__(self, embed_dim, max_seq_len, num_rep, vocab_size, padding_idx, gpu=False, dropout=0.25):\n",
    "        super(RelGAN_D, self).__init__(embed_dim, vocab_size, dis_filter_sizes, dis_num_filters, padding_idx,\n",
    "                                       gpu, dropout)\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.feature_dim = sum(dis_num_filters)\n",
    "        self.emb_dim_single = int(embed_dim / num_rep)\n",
    "\n",
    "        self.embeddings = nn.Linear(vocab_size, embed_dim, bias=False)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, n, (f, self.emb_dim_single), stride=(1, self.emb_dim_single)) for (n, f) in\n",
    "            zip(dis_num_filters, dis_filter_sizes)\n",
    "        ])\n",
    "\n",
    "        self.highway = nn.Linear(self.feature_dim, self.feature_dim)\n",
    "        self.feature2out = nn.Linear(self.feature_dim, 100)\n",
    "        self.out2logits = nn.Linear(100, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.init_params()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        \"\"\"\n",
    "        Get logits of discriminator\n",
    "        :param inp: batch_size * seq_len * vocab_size\n",
    "        :return logits: [batch_size * num_rep] (1-D tensor)\n",
    "        \"\"\"\n",
    "        emb = self.embeddings(inp).unsqueeze(1)  # batch_size * 1 * max_seq_len * embed_dim\n",
    "\n",
    "        cons = [F.relu(conv(emb)) for conv in self.convs]  # [batch_size * num_filter * (seq_len-k_h+1) * num_rep]\n",
    "        pools = [F.max_pool2d(con, (con.size(2), 1)).squeeze(2) for con in cons]  # [batch_size * num_filter * num_rep]\n",
    "        pred = torch.cat(pools, 1)\n",
    "        pred = pred.permute(0, 2, 1).contiguous().view(-1, self.feature_dim)  # (batch_size * num_rep) * feature_dim\n",
    "        highway = self.highway(pred)\n",
    "        pred = torch.sigmoid(highway) * F.relu(highway) + (1. - torch.sigmoid(highway)) * pred  # highway\n",
    "\n",
    "        pred = self.feature2out(self.dropout(pred))\n",
    "        logits = self.out2logits(pred).squeeze(1)  # [batch_size * num_rep]\n",
    "\n",
    "        return logits"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "machine_shape": "hm",
   "name": "GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
