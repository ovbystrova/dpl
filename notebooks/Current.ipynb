{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "from utils.dataloader import GANDataset, GenDataIter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"D:\\diploma\\github\\dpl\\data\" #\\real\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = GenDataIter(data=data_path,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2063e5dea48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = iterator.loader\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': tensor([[   1, 5171, 5852,  ...,    0,    0,    0],\n",
      "        [   1,  100, 5485,  ..., 5554, 1402,    0],\n",
      "        [   1, 3585,  830,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  141,  736,  ...,    0,    0,    0],\n",
      "        [   1, 3620, 3759,  ...,    0,    0,    0],\n",
      "        [   1, 3585, 5806,  ...,    0,    0,    0]]), 'target': tensor([[5171, 5852, 4559,  ...,    0,    0,    0],\n",
      "        [ 100, 5485, 5449,  ..., 1402,    0,    0],\n",
      "        [3585,  830, 4956,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 141,  736, 3026,  ...,    0,    0,    0],\n",
      "        [3620, 3759,  103,  ...,    0,    0,    0],\n",
      "        [3585, 5806,  698,  ...,    0,    0,    0]])}\n",
      "['<start>', 'when', 'it', 'comes', 'to', 'management', ',', 'i', 'â€™', 've', 'always', 'been', 'a', 'bigger', 'believer', 'in', 'fundamentals', 'than', 'fancy', '.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "for el in loader:\n",
    "    print(el)\n",
    "    x = el['input']\n",
    "    \n",
    "    for token in x:\n",
    "        print([iterator.idx2word[str(l.item())] for l in token])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator.word2idx['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<start>', 'when', 'it')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator.idx2word['1'], iterator.idx2word['5171'], iterator.idx2word['5852']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.RelGAN_G import RelGAN_G\n",
    "MAX_SEQ_LEN = 50\n",
    "PAD_IDX = 0\n",
    "VOCAB_SIZE = 6330\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if_cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = RelGAN_G(mem_slots=1, num_heads=2, head_size=256, embedding_dim=32, hidden_dim=32,\n",
    "                            vocab_size=VOCAB_SIZE, max_seq_len=MAX_SEQ_LEN, padding_idx=PAD_IDX, gpu=if_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.RelGAN_D import RelGAN_D\n",
    "dis = RelGAN_D(embed_dim=64, \n",
    "               max_seq_len=MAX_SEQ_LEN,\n",
    "               num_rep=64, \n",
    "               vocab_size=VOCAB_SIZE, \n",
    "               padding_idx=PAD_IDX, \n",
    "               weights = 'uniform',\n",
    "               gpu=if_cuda, \n",
    "               dropout=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "from models.instructor import RelGANInstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructor = RelGANInstructor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GENERATOR MLE TRAINING\n",
      "[MLE-GEN] epoch 0 : pre_loss = 5.4460, BLEU-[2, 3, 4, 5] = [0.403, 0.131, 0.077, 0.057], NLL_gen = 3.2112, NLL_div = 2.9414, Self-BLEU-[2, 3, 4] = [0.224, 0.084, 0.057]\n",
      "[MLE-GEN] epoch 1 : pre_loss = 2.7335, BLEU-[2, 3, 4, 5] = [0.653, 0.343, 0.179, 0.112], NLL_gen = 1.9271, NLL_div = 1.9373, Self-BLEU-[2, 3, 4] = [0.336, 0.138, 0.077]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-969fcea89044>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minstructor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\diploma\\github\\dpl\\models\\instructor.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;31m#===PRE-TRAINING (GENERATOR)===\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Starting GENERATOR MLE TRAINING'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_chechpoints/generator_mle'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\diploma\\github\\dpl\\models\\instructor.py\u001b[0m in \u001b[0;36mpretrain_generator\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;31m# ===Train===\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[0mpre_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_gen_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmle_criterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;31m# ===Test===\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\diploma\\github\\dpl\\models\\instructor.py\u001b[0m in \u001b[0;36mtrain_gen_epoch\u001b[1;34m(self, model, data_loader, criterion, optimizer)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\diploma\\github\\dpl\\models\\instructor.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(opt, loss, model, retain_graph)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLIP_NORM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Interference\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Interference\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "instructor._run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6930944919586182"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructor.adv_train_generator(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6930819153785706"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructor.adv_train_discriminator(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instructor.gen.sample()\n",
    "from utils.dataloader import GANDataset, GenDataIter\n",
    "from utils.preprocess import *\n",
    "SAMPLES_NUM = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "eval_samples = instructor.gen.sample(SAMPLES_NUM, 4 * BATCH_SIZE)\n",
    "# gen_data = GenDataIter(eval_samples, batch_size=BATCH_SIZE)\n",
    "# gen_tokens = tensor_to_tokens(eval_samples, instructor.idx2word_dict)\n",
    "# gen_tokens_s = tensor_to_tokens(instructor.gen.sample(200, 200), instructor.idx2word_dict)\n",
    "\n",
    "# # Reset metrics\n",
    "# # self.bleu.reset(test_text=gen_tokens, real_text=instructor.test_data.tokens)\n",
    "# instructor.nll_gen.reset(instructor.gen, instructor.train_data.loader)\n",
    "# instructor.nll_div.reset(self.gen, gen_data.loader)\n",
    "# instructor.self_bleu.reset(test_text=gen_tokens_s, real_text=gen_tokens)\n",
    "# instructor.ppl.reset(gen_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tokens = tensor_to_tokens(eval_samples, instructor.idx2word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['â€™', 'second-', 'racing', 'of', 'our', 'mayor', 'bullets', 'oil', 'prices', 'weighed', ',', 'and', 'he', 'found', 'of', 'this', 'over', 'a', 'pep', 'talk', 'interviews', '4', 'at', 'a', 'record', 'tribe', 'was', 'driven', 'service', 'is', 'sent', 'of', 'making', 'potash', '.']\n",
      "\n",
      "['happy', 'the', 'democratic', 'murder', 'left', '``', 'the', 'tricks', 'don', 'hit', '.']\n",
      "\n",
      "['``', 'these', 'youngsters', 'â€™', 's', 'weekend', '.']\n",
      "\n",
      "['the', 'newspaper', 'zoo', 'it', 'is', 'accused', \"'s\", \"'s\", 'right', '.']\n",
      "\n",
      "['jul', '4', '4', ',', 'all', 'of', 'the', 'game', 'was', 'hit', 'hard', '.']\n",
      "\n",
      "['rowe', 'the', 'powerful', 'is', 'up', 'this', 'was', 'beaten', 'affair', 'by', ',', 'screaming', 'when', 'it', 'was', '225', 'found', 'for', 'biting', 'treat', '.']\n",
      "\n",
      "['the', 'dow', 'jones', 'industrial', 'unpredictable', 'up', 'the', 'hearing', 'ended', 'site', 'will', 'be', 'of', 'illustrative', ',', 'joined', 'if', ',', 'officials', ',', 'would', 'to', 'be', 'up', 'the', 'situation', 'grill', '.']\n",
      "\n",
      "['routing', 'adam', 'malia', 'a', 'bigger', 'have', 'been', 'the', 'search', 'engine', 'to', 'expect', 'feel', '.']\n",
      "\n",
      "['the', 'black', 'francis', 'part', 'of', 'his', 'do', 'season', 'â€™', 's', 'alma', 'up', 'â€™', 's', 'public', 'events', 'at', 'the', 'end', ',', 'et', 'msn', 'for', 'south', 'tampa', 'mansion', 'on', 'sale', 'earlier', 'and', 'warned', 'of', 'the', 'flatbed', 'places', 'of', 'duncan', ',', 'while', 'dishing', ',', 'ecuador', ',', 'the', 'catholic', 'church', 'was', 'of', 'the', 'trip']\n",
      "\n",
      "['suarez', 'it', 'was', 'that', 'defined', 'rob', 'gronkowski', \"'s\", 'sex-discrimination', 'for', 'biting', 'the', 'nation', 'national', 'committee', 'government', 'especially', 'carnegie', 'a', 'family', 'affair', 'in', 'the', 'transportation', '.', \"'\"]\n",
      "\n",
      "['many', 'banks', 'prepared', 'contingency', 'plans', 'and', 'robbed', 'the', 'kong', '.']\n",
      "\n",
      "['extensions', 'came', 'jazeera', 'english', 'encouraged', 'attendees', '--', 'truck', 'service', ',', 'employee', 'wounded', 'a', 'bigger', 'will', 'start', 'for', 'the', 'of', 'baby']\n",
      "\n",
      "[':', 'ezra', 'shaw', 'for', 'redstone', 'to', 'test', 'as', 'said', 'the', 'por', 'will', 'be', 'of', 'deep', 'friends', 'and', 'top', 'committee', 'officials', '.']\n",
      "\n",
      "['if', ',', 'laughed', ',', 'said', 'state', 'a', 'spotted', 'of', 'pokÃ©mon', 'the', 'internet', 'state', '.']\n",
      "\n",
      "['when', 'andrew', 'rob', 'gronkowski', 'that', 'a', 'considerable', 'news', 'â€“', ',', 'mostly', 'she', 'the', 'berkshires', 'at', 'san', 'francisco', ',', 'who', \"'ve\", ',', 'do', 'his', 'south', 'tampa', 'mansion', 'night', '.']\n",
      "\n",
      "['updated', 'apr', '26', 'on', 'had', 'force', 'history', 'and', 'cause', 'season', 'driver', 'will', 'in', 'more', 'than', 'â€™', 's', 'largest', 'last', 'not', '.']\n",
      "\n",
      "['a', 'jury', '.']\n",
      "\n",
      "['the', 'email', 'involved', 'celebrated', 'received', ',', 'so', 'greatly', '``', 'dirty', 'last', 'in', '34', 'took', '(', ')', '(', 'ocdc', '.']\n",
      "\n",
      "['the', 'ads', 'who', 'process', 'trying', 'hitting', 'refugee', 'in', 'court', 'at', 'a', 'pre-dawn', 'waiting', 'of', 'clergy', 'that', 'could', '$', 'representatives', 'used', 'to', 'find', 'cancerous', 'at', \"'s\", 'just', 'personalities', ',', 'parliament', 'criminal', 'activity', 'activity', 'on', 'the', 'holiday', 'guidelines', 'say', 'in', '1988', 'the', 'car', 'they', 'called', 'they', 'didn', 'what', 'stock', 'be', 'of', 'averting']\n",
      "\n",
      "['ad', 'â€œ', 'the', 'unit', 'with', 'the', 'movie', 'high-profile', 'ex-nfl', '0.2', 'weekend', 'her', '.', 'and', 'depress', 'investment', 'confidence', '.']\n",
      "\n",
      "['\\u200bthe', 'liberal', 'made', 'straight', '.']\n",
      "\n",
      "['but', '``', 'thursday', ',', 'when', 'rob', 'gronkowski', 'by', 'clicking', 'that', 'keys', 'it', 'in', 'more', 'than', '$', '3.5', ',', 'among', 'trump', 'is', 'for', 'a', 'of', 'the', 'holiday', 'stretch', '(', 'ap', 'also', ')', '.']\n",
      "\n",
      "['the', 'british', 'attempts', 'house', 'of', 'himself', 'a', 'more', 'of', 'dropped', 'currently', 'home', 'on', 'wednesday', 'that', 'will', 'camera', 'plucking', 'would', 'up', 'said', 'and', 'the', '.']\n",
      "\n",
      "['yet', 'before', 'for', 'on-pitch', 'misbehavior', '.']\n",
      "\n",
      "['belmont', 'was', 'flattened', 'â€˜', 'â€™', 't', 'stop', 'there', ',', 'in', 'washington', 'richard', 'sherman', '#', '25', '.']\n",
      "\n",
      "['the', 'state', 'of', 'art', 'during', 'squad', 'to', 'witnesses', 'leg', 'just', 'was', 'that', 'officials', 'say', 'from', 'air']\n",
      "\n",
      "['when', 'rob', 'gronkowski', 'and', 'lindsay', 'it', 'could', 'severely', 'disrupt', 'bilateral', 'images', '.']\n",
      "\n",
      "['how', 'i', \"'ll\", 'even', ',', 'at', 'a', '9-year-old', 'and', 'unlikely', 'try', 'on', 'the', 'hollywood', 'palladium', ',', 'whose', 'in', 'the', 'complimentary', 'leg', 'racing', 'it', 'box', 'office', 'smash', 'the', 'side', 'last', ')', 'swell', 'will', '.', 'air', 'in', 'bayous', ',', 'jumping', 'sallet', 'on', 'the', 'city', 'in', 'the', 'show', 'rule', 'screenplay', 'of', 'tickets', 'bat']\n",
      "\n",
      "['volkswagen', \"'s\", 'blink-182', 'arrived', '(', ')', 'moussaoui', 'and', 'â€™', 's', 'parents', 'remember', 'in', 'the', 'new', 'york', 'times', 'service', 'for', 'economic', 'says', '(', 'cnnmoney', '.']\n",
      "\n",
      "['they', '.']\n",
      "\n",
      "['for', 'the', 'u.s.', 'patent', ',', 'state', ',', 'say', ',', 'study', 'monster', ',', 'you', 'see', 'â€™', 's', 'metlife', 'â€™', 's', 'the', 'latest', 'high-profile', 'ex-nfl', 'that', '.']\n",
      "\n",
      "['photo', 'reporter', 'their', 'ended', 'this', 'slots', 'size', 'of', 'football', '.']\n",
      "\n",
      "['``', 'the', 'burkini', 'for', 'and', 'state', 'their', 'clooney', 'and', 'monsters', 'distributed', 'in', \"'s\", 'the', 'sexy', 'of', 'distant', 'microsoft', '.']\n",
      "\n",
      "['profile', 'menachem', 'to', 'earlier', 'this', 'week', 'pm', 'est', '--', 'that', 'time', 'that', 'they', 'will', 'be', 'slays', 'leaving', 'at', '04:35', 'about', ',', 'the', 'media', 'and', 'was', 'of', 'the', 'riots', 'have', ',', 'an', 'nba', 'again', 'que', 'fuere', 'in', 'their', 'voice', 'and', 'its', 'state', '11', \"'s\", 'involvement', 'is', 'still', 'haunting', 'bathers', ',', 'at']\n",
      "\n",
      "['with', 'at', 'the', 'commonwealth', ',', 'it', 'was', 'at', 'the', 'home', 'an', 'and', 'it', 'at', 'â€™', 's', ',', 'singapore', 'have', 'prompted', 'of', 'josh', 'an', 'honorary', 'creada', 'american', 'you', 'â€™', 's', 'victory', ',', 'you', 'actively', 'disliked', 'of', 'one', 'of', 'child', 'abuse', 'victim', 'reason', 'dollars', '.']\n",
      "\n",
      "['victoria', 'in', 'an', 'got', 'growth', 'for', 'the', 'burkini', '$', '700', 'by', ',', 'of', 'a', 'criminal', 'activity', 'activity', 'is', 'on', 'global', 'warming', 'in', 'washington', '?']\n",
      "\n",
      "['the', 'channels', \"'s\", 'very', 'devoted', 'wal-mart', 'celebrated', 'it', 'has', 'been', 'asked', 'that', 'am', 'for', 'great', 'at', 'the', 'chest', 'of', 'the', 'spring', 'won', 'austria-hungary', 'neighborhood', 'issue', 'the', 'snow', 'of', 'â€™', 't', 'stop', 'is', '.']\n",
      "\n",
      "['the', 'powerful', 'who', 'happy', 'â€™', 's', 'the', 'pistol', 'and', 'europe', ',', 'said', ',', 'â€™', 's', 'race', ',', 'tried', 'sales', 'tactics', 'shark', 'in', 'northeast', 'and', 'efficient', 'their', 'more', 'lenient', 'approach', 'would', 'troops', '(', 'able', 'came', 'out', '.']\n",
      "\n",
      "['brian', 'harkin', ',', '2', ',', 'especially', 'carnegie', 'hill', 'just', ',', 'according', 'to', 'what', 'you', 'was', 'flattened', 'by', 'was', 'hit', '.']\n",
      "\n",
      "['new', 'york', 'after', 'dallas', 'about', 'elon', 'musk', 'â€™', 't', 'getting', 'â€™', 's', 'killer', 'will', 'again', 'â€™', 's', 'part', 'swimsuit', 'men', 'from', 'football', 'says', 'from', 'that', 'buying', 'gas', 'the', 'animal', 'town', 'at', 'the', 'telephone', 'system', \"'s\", 'to', 'the', '.']\n",
      "\n",
      "['how', 'you', 'didn', 'â€™', 's', 'common', ',', 'blackberries', 'and', 'presented', 'of', 'the', 'told', 'of', 'the', 'the', 'body-concealing', 'bank', 'an', 'hour', 'couldn', 'the', 'hostage', 'government', 'agencies', '.', 'says']\n",
      "\n",
      "['ask', ',', 'just', 'words', 'of', 'our', 'weekend', 'that', 'global', 'warming', 'officials', ',', '2013', ',', 'at', 'apple', 'hour', ',', '7:59am', 'kimble', ',', 'because', 'for', 'biting', 'hit', 'victory', ',', 'covering', 'total', 'was', 'flattened', 'richard', 'sherman', '#', '25', ',', 'at', 'comer', 'the', 'unfolding', ',', 'especially', 'carnegie', 'the', 'flight', 'risk']\n",
      "\n",
      "['when', 'these', 'wear', 'are', 'becoming', 'all', ',', 'tex.', 'to', 'waiting', ',', 'officials', 'for', 'passengers', 'air', 'said', 'it', 'was', 'that', 'he', 'in', 'rural', 'worldwide', ',', 'the', 'commercial', 'real', 'estate', 'running', 'was', 'an', 'apartment', 'news', 'staff', '/', 'ap', 'sterlington', 'in']\n",
      "\n",
      "['quito', 'the', 'family', 'in', 'what', 'happens', 'the', 'government', 'and', 'over', 'site', 'to', 'over', 'be', 'on', 'the', 'and', 'sodomy', 'of', 'animal', 'winkler', ',', 'obama', ',', 'say', 'last', 'some', 'ridiculously', 'jaded', 'fool', 'to', 'the', 'data', \"'s\", ',', 'or', 'any', 'affinity', 'probably', 'in', 'a', 'strategic', 'and', 'debbie', 'wasserman', 'to', 'extend', 'initial', 'and', 'state']\n",
      "\n",
      "['malia', ',', 'march', 'â€“', 'though', 'freedom', 'and', 'assorted', 'in', 'london', 'even', 'their', 'music', 'of', 'the', 'swagger', 'giant', 'of', 'our', 'greenhouse', '2013', 'to', 'inquire', 'at', '$', '1.3', 'in', \"'s\", 'their', 'hospital', 'it', 'carries', 'the', 'unfolding', 'on', 'march', 'to', 'be', 'astonishes', \"''\", 'jackson', 'that', 'there', ',', 'probably', 'electrocuted', 'member', 'during', 'at', ',']\n",
      "\n",
      "['richard', 'sherman', '#', '25', 'up', 'at', 'school', 'black', \"'s\", 'imagination', '.', 'sageunay']\n",
      "\n",
      "['where', 'two', 'they', 'didn', ',', 'the', 'town', ',', '2', 'columnpg=sptfb4ap=1089size=300x250', 'pm', 'est', 'and', 'state', 'days', 'when', 'be', ':', 'made', 'this', 'barely', 'europe', 'came', 'in', 'on', 'monday', 'way', 'and', 'hopkins', 'crook', \"''\", 'jackson', 'to', 'show', 'in', 'everyone', 'in', 'order', 'several', 'deals', 'shows', ',', 'said', '.']\n",
      "\n",
      "['integrated', 'â€™', 's', 'alma', 'mater', ',', 'which', 'overturned', 'two', 'behind', 'at', 'the', 'sight', 'continue', 'after', 'on', 'saturday', 'a', 'web', 'from', 'that', 'is', 'them', '.']\n",
      "\n",
      "['is', 'winner', 'arms', 'in', 'by', 'the', 'chicago', 'tribune', 'reported', 'by', 'the', 'region', 'morning', 'at', 'the', 'curtain', 'of', 'the', 'feast', 'game', 'at', 'the', 'state', 'at', 'white', 'house', \"'s\", ',', 'and', 'the', 'government', 'agencies', 'that', 'prizes', 'novelty', '.', \"''\", '--', 'only', 'east', 'at', 'that', ',', 'will', 'be', 'up', 'this', 'friday', 'to', '.']\n",
      "\n",
      "['has', 'chicago', 'â€™', 's', 'alma', 'mater', '.']\n",
      "\n",
      "['following', 'it', 'of', 'when', 'rob', 'gronkowski', 'was', 'given', 'another', 'long', 'layoff', 'to', 'find', 'a', 'punk-rock', 'et', 'decision', 'park', 'ready', 'recently', 'building', 'staff', '/', 'ap', 'in', 'asia', 'the', 'misconception', 'it', 'comes', 'themselves']\n",
      "\n",
      "['the', 'small', 'giuffridu', 'measure', 'soda', 'it', 'will', 'gulf', 'at', 'the', 'â€“', 'with', 'local', 'in', 'crimea', 'of', 'his', 'republican', 'carmichael', 'mine', 'made', '.']\n",
      "\n",
      "['it', 'was', 'â€™', 's', 'army', 'no', 'surprise', 'the', 'park', 'they', 'will', 'immediately', 'improve', 'safety', 'a', 'defended', 'for', 'a', 'way', 'at', 'pm', 'est', 'deals', ',', 'italy', 'and', 'jagalingou', 'is', 'just', ',', 'ending', 'out', 'at', 'the', 'magic', 'negro', ',', 'average', 'jumped', '208', 'points', '(', 'ocdc', 'up', 'only', 'the', 'united', 'states', 'post', 'in']\n",
      "\n",
      "['bicarbonate', 'the', 'stars', 'of', 'the', 'united', 'states', '.']\n",
      "\n",
      "['``', 'these', 'was', 'bill', ',', 'but', 'it', 'was', 'a', 'hit', 'movies', ',', 'said', 'it', 'was', 'beaten', 'the', 'most', 'intriguing', 'literary', 'mysteries', \"'s\", '2-2', 'draw', '.']\n",
      "\n",
      "['his', 'sacrifice', 'chang', '.']\n",
      "\n",
      "['washington', 'the', 'poetry', 'brian', ',', 'out', 'in', 'more', '.']\n",
      "\n",
      "['voters', '4', 'actively', 'that', 'just', 'to', 'a', '9-year-old', 'girl', 'emergency', 'management', 'has', '20', 'metropolitan', 'for', 'biting', 'to', 'an', 'obese', 'the', 'times', ':', 'stop', 'rights', 'organizations', '.']\n",
      "\n",
      "['\\u200bthe', 'liberal', 'with', 'a', 'promise', 'of', 'heavily', 'sky', 'in', 'the', 'nominee', \"'s\", 'role', 'networks', 'to', 'find', 'customers', 'to', 'them', 'the', 'hulking', 'basketball', '.']\n",
      "\n",
      "['tempur-pedic', '.']\n",
      "\n",
      "['delune06', 'the', 'race', 'at', 'small', 'tried', ':', 'of', 'the', 'daily', 'the', 'collision', 'member', 'of', 'depression', 'south', 'american', 'pilgrimage', \"'s\", 'very', 'devoted', 'shows', 'it', 'was', 'decided', 'zacarias', 'moussaoui', 'has', 'recently', 'been', 'a', 'couple', 'released', '40', 'the', 'building', 'there', 'family', 'times', 'reporter', 'more', 'than', 'of', 'the', 'severity', 'of', 'luis', 'for', 'on-pitch', 'misbehavior']\n",
      "\n",
      "['this', '4', ',', 'she', 'pleads', ',', 'as', 'a', 'class-action', '.', \"''\", 'of', 'the', 'latest', 'high-profile', 'ex-nfl', 'plan', 'fall', ',', 'determined', '.']\n",
      "\n",
      "['(', 'the', 'site', 'first', 'leg', 'can', 'night', ',', 'spotted', 'on', 'chicago', 'down', ',', 'on', 'the', 'need', 'of', 'unsuspecting', 'â€™', 's', 'alma', 'mater', 'for', 'criminal', 'ouimet', 'at', 'much', 'show', 'huge', 'democrats', ',', 'especially', 'has', 'been', 'stored', ',', 'killing', 'supposed', '.']\n",
      "\n",
      "['the', 'berkshires', 'horn', 'turkish', 'hands', ',', 'while', 'australia', 's', '&', 'p', 'asx/200', 'fell', '0.8']\n",
      "\n",
      "['one', 'of', 'the', 'of', 'the', '17-year-old', 'competition', '.']\n",
      "\n",
      "['much', 'have', 'been', 'shot', 'on', 'such', 'detonation', 'of', 'millions', 'for', 'biting', 'a', 'u.s.', 'man', 'rather', 'than', 'people', ',', 'size', 'up', 'it', 'was', 'targeted', 'when', 'this', 'at', 'was', 'flattened', 'â€™', 's', 'iconic', 'dependent', 'a', 'draft', 'summary', ',', 'were', 'the', 'ready', 'lit', 'symmtery', 'without', 'against', 'the', 'tampa', 'bay', 'times', 'at', 'together', 'to']\n",
      "\n",
      "['thursday', 'is', 'are', 'would', 'powers', 'meeting', 'they', 'for', 'the', 'cyber-espionage', 'up', 'the', 'internet', 'search', 'it', 'and', '``', 'costs', \"''\", 'toward', 'over', 'the', 'powerful', 'new', 'york', ',', 'officials', 'say', ',', 'yield', 'on', 'march', 'just', '100-yards', 'behind', ':', 'australian', 'children', 'richard', 'engel', 'having', 'thursday', \"'s\", 'choked', ',', 'a', 'family', 'affair', 'of', 'atlanta']\n",
      "\n",
      "['nbc', ')', 'released', '40', 'competition']\n",
      "\n",
      "['``', 'it', \"'s\", 'very', 'difficult', 'to', 'enforce', 'something', ',', \"''\", 'that', 'it', 'is', 'militant', 'that', 'said', 'there', 'it', 'was', 'a', 'dense', 'said', 'from', 'seen', 'that', 'but', 'it', 'also', 'at', 'its', 'right', 'â€“', 'night', 'to', 'from', 'the', 'report', 'has', 'academic', 'the', 'backyard', 'was', 'daughter', '.']\n",
      "\n",
      "['congress', 'is', 'shooting', 'u.s.', 'attorney']\n",
      "\n",
      "['the', 'brand', 'â€œ', 'requests', 'from', 'of', 'their', 'race', 'for', '(', 'family', 'that', 'what', 'they', 'didn', 'â€™', 's', 'many', 'at', 'behind', ',', 'said', 'was', 'the', 'miami', 'heat', '.']\n",
      "\n",
      "['the', 'u.s.', 'girl', 'in', '2013', ',', 'which', 'flick', 'questions', 'the', 'november', 'who', 'was', 'of', 'it', 'flew', ',', 'winding', ',', 'autographs', 'and', 'many', 'a', 'regional', 'u.s.', 'patent', 'racing', ',', 'by', 'everyone', 'in', 'at', 'the', 'state', 'racing', 'rob', 'gronkowski', 'it', 'ca', \"n't\", 'which', 'alleges', 'what', 'and', 'announced', ',', 'found', 'by', 'at', 'during']\n",
      "\n",
      "['nbc', 'john', 'against', 'the', 'will', 'on', 'the', 'startup', 'sold-out', 'of', 'the', 'atlantic', 'took', 'at', 'a', 'big', 'discussion', 'the', 'biggest', 'to', 'hit', 'bill', '--', '(', ')', 'shows', '?']\n",
      "\n",
      "['yet', 'this', 'week', 'columnpg=sptfb4ap=1089size=300x250', 'at', '04:35', 'a', 'of', 'the', 'end', 'who', 'won', 'visit', 'earlier', 'during', ',', 'â€™', 's', 'common', '(', 'the', 'capital', 'to', 'little', 'rob', 'astorino', 'were', 'probably', 'electrocuted', 'to', 'the', 'magic', 'negro', '--', 'of', 'senator', 'jeff', 'sessions', 'at', 'the', 'unfolding', 'of', 'carrying', 'years', 'has', 'the', 'hollywood', 'palladium', '.']\n",
      "\n",
      "['(', 'cnnmoney', 'and', 'control', ')', ',', 'the', 'upper', 'east', 'side', 'at', 'least', \"n't\", 'motors', 'to', 'quickly', 'machines', 'a', 'refugee', 'them', 'of', 'discrimination', 'to', 'that', 'the', 'dick', 'cavett', 'on', '40', 'music', 'to', 'inquire', 'thought', 'interest', 'again', 'that', 'in', 'fundamentals', '22', 'for', 'aggressive', 'of', 'making', 'contributed', '.']\n",
      "\n",
      "['antonio', 'is', 'one', 'themselves', 'floor', 'injuries', 'pm', 'est', 'from', 'at', 'odds', 'such', 'it', 'ca', 'for', 'the', 'upper', 'east', 'side', 'it', 'ban', 'as', 'the', 'hit', 'zombie-themed', 'television', 'series', 'to', 'enforce', ',', 'who', 'opens', 'was', 'not', ',', 'while', 'site', ',', 'randwick', 'explore', 'company']\n",
      "\n",
      "['at', 'the', 'bodies', 'in', 'an', 'mudslide', 'hands', 'a', 'blog', 'interior', 'ended', 'action', 'peck', ',', 'whose', '66', 'to', 'escape', 'on', 'the', 'negotiations', '!', '.']\n",
      "\n",
      "['signs', 'was', 'cnn', '23', 'with', 'of', 'an', 'out', 'a', 'tickets', 'a', 'of', 'heavily', 'tattooed', 'by', 'the', 'u.s.', 'history', 'in', 'your', 'living', 'at', 'they', ',', 'it', ',', 'said', 'in', 'washington', '(', 'r.', ')', ',', 'whether', 'were', 'bat', '(', 'that', ',', 'starting', 'aggrieved', 'certainty', 'brendan', 'to', 'jump', 'a', 'new', 'year', 'on', 'sale']\n",
      "\n",
      "['jayah', 'you', 'â€“', 'pope', 'francis', 'wraps', 'times', 'has', 'already', 'to', 'his', 'work', 'night', 'for', 'at', 'a', 'century', 'that', 'attacks', 'vacationers', 'build', ',', 'the', 'd.c', 'of', 'the', 'century', 'moments', 'in', 'not', ',', 'the', 'rust', 'water', 'flowing', 'in', 'conjunction', 'at', 'rowe', 'major', '240,745', 'in', 'on', 'show', 'time', '.']\n",
      "\n",
      "['nbc', 'beans', 'this', ')', 'weak', 'euro/strong', 'dollar', 'company', 'by', 'states', 'experts', 'and', 'in', 'a', 'state', 'of', 'and', 'monsters', 'and', 'and', 'medical', 'center', 'of', 'â€™', 't', 'believe', 'a', 'boy', 'of', 'more', 'than', 'three', 'is', 'yet', 'of', 'swift', 'year', '.']\n",
      "\n",
      "['oso', 'donald', 'news', 'on', 'won', ':', 'council', 'in', 'new', 'york', 'briefing', 'year', 'a', 'car', 'of', 'are', 'posted', 'it', 'to', 'push', 'give', 'it', 'in', 'a', 'hail', '(', 'cnnmoney', ')', '--', 'obama', 'the', 'and', 'mohawk-sporting', 'fans', 'waiting', 'the', 'parliamentary', 'department', 'and', 'japan', 'women', 'against', 'ended', 'is', 'at', 'the', 'brand', 'friday', \"'s\", 'at']\n",
      "\n",
      "['the', 'occasion', 'is', 'walsh', 'â€œ', 'said', ',', 'a', 'salt', 'that', 'to', 'live', '.']\n",
      "\n",
      "['sony', 'show', 'where', 'a', 'emotions', ',', 'while', 'dishing', 'county', 'park', ',', 'to', 'be', 'deal', 'daughter', '``', 'box', 'wrong', 'on', 'be', \"'s\", 'to', 'very', \"''\", 'would', 'of', 'know', 'is', 'already', 'spotted', ',', 'was', 'pronounced', 'the', 'nation', \"'s\", 'tense', 'relations', \"'s\", 'on', '911.', ',', 'socal', 'when', 'rob', 'gronkowski', \"'s\", 'stadium', 'on', 'october']\n",
      "\n",
      "['her', 'where', 'a', 'trendâ€”are', 'doing', ',', 'who', 'said', 'money']\n",
      "\n",
      "[\"'s\", 'for', 'all', '.']\n",
      "\n",
      "['tradersâ€”all', 'an', 'building', 'â€™', 's', 'rifle', 'already', 'say', 'has', 'been', 'producing', \"'ll\", 'has', '.']\n",
      "\n",
      "['a', 'special', 'that', 'used', 'a', 'wild', '41-35', '.']\n",
      "\n",
      "['john', 'pennington', 'a', 'scene', 'that', 'incident', 'are', 'acting', 'and', 'inmate', 'a', '9.62', 'that', 'clog', ',', 'was', 'killed', ',', 'officials', 'say', '(', 'nyse', '.']\n",
      "\n",
      "['but', 'his', 'home', '.']\n",
      "\n",
      "['arlington', 'with', 'a', 'shot', 'at', 'one', 'step', 'only', ')', ',', 'and', 'even', \"'s\", 'call', 'in', 'a', 'hail', 'game', 'at', '``', 'these', 'influential', 'its', 'ancestral', 'lands', \"'s\", ',', 'especially', 'carnegie', 'hill', 'yellow', 'the', 'religious', 'associations', 'from', 'in', 'the', 'chest', 'of', 'appeals', 'about', 'south', 'tampa', 'mansion', 'on', 'monday', 'that', 'opportunity', '.']\n",
      "\n",
      "['already', 'grown', 'has', 'been', 'and', 'announced', 'this', ',', 'is', 'still', 'to', 'use', 'your', 'code-slinging', 'skills', 'on', 'the', 'backyard', 'men', 'â€”', 'and', 'a', 'family', 'affair', '.']\n",
      "\n",
      "['most', 'treatments', 'california', 'women.Ã¢\\x80\\x9d', 'debut', 'television', '.']\n",
      "\n",
      "['drax', 'these', 'youngsters', 'was', 'dead', 'thought', '.']\n",
      "\n",
      "['nbc', 'the', 'four', 'women', 'decided', 'zacarias', 'moussaoui', ',', 'said', 'about', '4', 'p.m.', 'made', ',', 'functionality', 'it', 'more', \"'s\", 'deputy', ',', 'said', 'and', 'kirin', ',', \"''\", 'jackson', 'avenue', \"n't\", ',', 'a', 'league', 'of', 'people', 'that', '9th', 'the', 'negro', 'court', '(', 'for', 'men', 'president', 'to', '.']\n",
      "\n",
      "['season', '(', 'dos', ')', 'the', 'unfolding', 'was', 'targeted', 'acting', '.']\n",
      "\n",
      "['mercer', 'the', 'young', 'incubator', 'men', 'on', 'cowper', 'was', 'driven', '.']\n",
      "\n",
      "['when', 'rob', 'gronkowski', 'took', 'news', \"'s\", 'house', 'at', 'the', 'embassy', ',', 'texas', 'by', 'george', 'necessarily', 'at', 'does', \"n't\", 'necessarily', 'agree', ',', 'say', 'post', ',', 'upending', 'said']\n",
      "\n",
      "['newt', 'new', 'u', 'just', 'having', '.']\n",
      "\n",
      "['``', 'of', ',', 'the', 'sierra', 'madre', 'just', \"'s\", 'took', 'call', 'at', 'a', 'small', 'earthquake', 'struck', 'obama', 'at', \"'s\", 'choice', 'depend', 'and', 'rebranding', 'hundreds', 'they', 'will', 'â€”', 'at', 'odds', 'bay', 'times', 'shot', 'video', 'policy', 'harwood', ')', '.']\n",
      "\n",
      "['a', 'jury', 'of', 'the', 'derailment', 'site', 'site', 'for', 'the', 'lives', 'any', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in gen_tokens:\n",
    "    print(el)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
