{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install --upgrade wandb\n",
    "# !wandb login "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from transformers import BertTokenizer, BertModel, GPT2Model, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization = 'gpt2'\n",
    "pretrained_weights = 'gpt2'\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_weights, unk_token='<unk>', eos_token='<pad>', pad_token='<pad>', bos_token='<start>')\n",
    "# pad_index = tokenizer.convert_tokens_to_ids('<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bos_token': '<start>', 'eos_token': '<pad>', 'unk_token': '<unk>', 'pad_token': '<pad>'}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.special_tokens_map)\n",
    "# tokenizer.bos_token = '<start>'\n",
    "# tokenizer.eos_token = '<pad>'\n",
    "# tokenizer.pad_token = '<pad>'\n",
    "# tokenizer.unk_token = '<unk>'\n",
    "# tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'<start>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1ce344c20554>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'<start>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: '<start>'"
     ]
    }
   ],
   "source": [
    "vocab['<start>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'<unk>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-46b7e48bc341>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'<unk>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: '<unk>'"
     ]
    }
   ],
   "source": [
    "vocab['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50259'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {key: str(value) for key,value in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50260"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inverse = {str(value):key for key,value in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_inverse['50259']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens:  50260\n"
     ]
    }
   ],
   "source": [
    "with open('data/wi_gpt.txt', 'w', encoding='utf-8') as dictout:\n",
    "    dictout.write(str(vocab))\n",
    "with open('data/iw_gpt.txt', 'w', encoding='utf-8') as dictout:\n",
    "    dictout.write(str(vocab_inverse))\n",
    "print('total tokens: ', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess import load_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"data\"\n",
    "w2i, i2w = load_dict(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50260, 50260)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2i), len(i2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40,\n",
       " 1842,\n",
       " 6844,\n",
       " 290,\n",
       " 256,\n",
       " 271,\n",
       " 318,\n",
       " 312,\n",
       " 65,\n",
       " 26,\n",
       " 2162,\n",
       " 75,\n",
       " 73,\n",
       " 70,\n",
       " 26,\n",
       " 87,\n",
       " 73,\n",
       " 2162,\n",
       " 75,\n",
       " 10025,\n",
       " 73,\n",
       " 26]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = tokenizer.encode('I love dogs and tis isidb; ;ljg;xj ;lkgj;')\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'Ġlove',\n",
       " 'Ġdogs',\n",
       " 'Ġand',\n",
       " 'Ġt',\n",
       " 'is',\n",
       " 'Ġis',\n",
       " 'id',\n",
       " 'b',\n",
       " ';',\n",
       " 'Ġ;',\n",
       " 'l',\n",
       " 'j',\n",
       " 'g',\n",
       " ';',\n",
       " 'x',\n",
       " 'j',\n",
       " 'Ġ;',\n",
       " 'l',\n",
       " 'kg',\n",
       " 'j',\n",
       " ';']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = tokenizer.tokenize('I love dogs and tis isidb; ;ljg;xj ;lkgj;')\n",
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1842"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['Ġlove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " ' love',\n",
       " ' dogs',\n",
       " ' and',\n",
       " ' t',\n",
       " 'is',\n",
       " ' is',\n",
       " 'id',\n",
       " 'b',\n",
       " ';',\n",
       " ' ;',\n",
       " 'l',\n",
       " 'j',\n",
       " 'g',\n",
       " ';',\n",
       " 'x',\n",
       " 'j',\n",
       " ' ;',\n",
       " 'l',\n",
       " 'kg',\n",
       " 'j',\n",
       " ';']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = [tokenizer.decode(x) for x in d]\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love dogs and tis isidb; ;ljg;xj ;lkgj;'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess import get_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = get_tokenized(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(',\n",
       " 'Po',\n",
       " 'ets',\n",
       " '&',\n",
       " 'Qu',\n",
       " 'ants',\n",
       " ')',\n",
       " 'ĠâĢĶ',\n",
       " 'ĠDavid',\n",
       " 'ĠThomas',\n",
       " 'Ġdigs',\n",
       " 'ĠB',\n",
       " 'H',\n",
       " 'AG',\n",
       " 's',\n",
       " 'ĠâĢĵ',\n",
       " 'Ġshort',\n",
       " 'Ġfor',\n",
       " 'Ġbig',\n",
       " ',',\n",
       " 'Ġhairy',\n",
       " ',',\n",
       " 'Ġaud',\n",
       " 'acious',\n",
       " 'Ġgoals',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import GANDataset, GenDataIter\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = GenDataIter(data=path,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1793cb1d7c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = iterator.loader\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': tensor([[    1, 39461,    82,  ..., 17168,    13,     0],\n",
      "        [    1,  2990,  8020,  ...,     0,     0,     0],\n",
      "        [    1,  1532,   345,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1, 29316,  6705,  ...,   905,   309, 10008],\n",
      "        [    1, 29387, 16988,  ...,     0,     0,     0],\n",
      "        [    1,  1544,   531,  ...,     0,     0,     0]]), 'target': tensor([[39461,    82,  4186,  ...,    13,     0,     0],\n",
      "        [ 2990,  8020,   470,  ...,     0,     0,     0],\n",
      "        [ 1532,   345,   447,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [29316,  6705,  2060,  ...,   309, 10008,    25],\n",
      "        [29387, 16988,  1139,  ...,     0,     0,     0],\n",
      "        [ 1544,   531,   262,  ...,     0,     0,     0]])}\n",
      "['\"', 'Brother', 's', 'ĠTom', ',', 'Ġleft', ',', 'Ġand', 'ĠRay', 'ĠMag', 'lio', 'zzi', ',', 'Ġshown', 'Ġin', 'Ġ1991', ',', 'Ġsay', 'Ġthey', \"'ll\", 'âĢ¦', 'Ġ(', 'Susan', 'ĠWalsh', ',', 'ĠAssociated', 'âĢ¦)', 'ĠThey', 'Ġwere', 'Ġa', 'Ġcouple', 'Ġof', 'Ġauto', 'Ġmechanics', 'Ġwith', 'Ġa', 'Ġpronounced', 'ĠBoston', 'Ġbro', 'gue', 'Ġand', ',', 'Ġimpro', 'bably', ',', 'Ġdegrees', 'Ġfrom', 'ĠMIT', '.', '!']\n"
     ]
    }
   ],
   "source": [
    "for el in loader:\n",
    "    print(el)\n",
    "    x = el['input']\n",
    "    \n",
    "    for token in x:\n",
    "        print([iterator.idx2word[str(l.item())] for l in token])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50258'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator.word2idx['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50260"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iterator.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"', 'they', 'had', '!')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator.idx2word['1'], iterator.idx2word['9930'], iterator.idx2word['18108'], iterator.idx2word['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50257'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator.word2idx['<start>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess import tokens_to_tensor, tensor_to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brother',\n",
       " 's',\n",
       " 'ĠTom',\n",
       " ',',\n",
       " 'Ġleft',\n",
       " ',',\n",
       " 'Ġand',\n",
       " 'ĠRay',\n",
       " 'ĠMag',\n",
       " 'lio',\n",
       " 'zzi',\n",
       " ',',\n",
       " 'Ġshown',\n",
       " 'Ġin',\n",
       " 'Ġ1991',\n",
       " ',',\n",
       " 'Ġsay',\n",
       " 'Ġthey',\n",
       " \"'ll\",\n",
       " 'âĢ¦',\n",
       " 'Ġ(',\n",
       " 'Susan',\n",
       " 'ĠWalsh',\n",
       " ',',\n",
       " 'ĠAssociated',\n",
       " 'âĢ¦)',\n",
       " 'ĠThey',\n",
       " 'Ġwere',\n",
       " 'Ġa',\n",
       " 'Ġcouple',\n",
       " 'Ġof',\n",
       " 'Ġauto',\n",
       " 'Ġmechanics',\n",
       " 'Ġwith',\n",
       " 'Ġa',\n",
       " 'Ġpronounced',\n",
       " 'ĠBoston',\n",
       " 'Ġbro',\n",
       " 'gue',\n",
       " 'Ġand',\n",
       " ',',\n",
       " 'Ġimpro',\n",
       " 'bably',\n",
       " ',',\n",
       " 'Ġdegrees',\n",
       " 'Ġfrom',\n",
       " 'ĠMIT',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tokenized[0]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[39461,    82,  4186,    11,  1364,    11,   290,  7760,  2944, 48590,\n",
       "         46218,    11,  3402,   287, 10249,    11,   910,   484,  1183,  1399,\n",
       "           357, 45842, 24104,    11, 10575, 38418,  1119,   547,   257,  3155,\n",
       "           286,  8295, 12933,   351,   257, 16293,  6182,  1379, 18701,   290,\n",
       "            11,  2015, 11921,    11,  7370,   422, 17168,    13,     0,     0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_tensor([t], w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2w['11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2w['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.RelGAN_G import RelGAN_G\n",
    "import configuration as cfg\n",
    "MAX_SEQ_LEN = cfg.MAX_SEQ_LEN\n",
    "PAD_IDX = cfg.PAD_IDX\n",
    "VOCAB_SIZE = 50260\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if_cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = RelGAN_G(mem_slots=1, num_heads=2, head_size=256, embedding_dim=32, hidden_dim=32,\n",
    "                            vocab_size=VOCAB_SIZE, max_seq_len=MAX_SEQ_LEN, padding_idx=PAD_IDX, gpu=if_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.RelGAN_D import RelGAN_D\n",
    "dis = RelGAN_D(embed_dim=64, \n",
    "               max_seq_len=MAX_SEQ_LEN,\n",
    "               num_rep=64, \n",
    "               vocab_size=VOCAB_SIZE, \n",
    "               padding_idx=PAD_IDX, \n",
    "               weights = 'uniform',\n",
    "               gpu=if_cuda, \n",
    "               dropout=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1204ae7691dd4ff38ed0ca5b94612cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c456706ae74cfeaed141fe1aa81d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "embeddings_pretrained = model.get_input_embeddings()\n",
    "\n",
    "embeddings_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_pretrained.weight.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.LSTM_D import LSTM_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ef __init__(self, vocab_size, embed_dim, hidden_size,\n",
    "      #           emb_pretrained, embeddings, max_seq_len, padding_idx, weights, gpu=cfg.if_cuda):\n",
    "    \n",
    "dis = LSTM_D(vocab_size=50260,\n",
    "            embed_dim=768,\n",
    "            hidden_size=256,\n",
    "            emb_pretrained = False,\n",
    "            embeddings = embeddings_pretrained,\n",
    "            max_seq_len=cfg.MAX_SEQ_LEN,\n",
    "            padding_idx=cfg.PAD_IDX,\n",
    "            weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.instructor_LSTM import LSTMInstructor\n",
    "instructor = LSTMInstructor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50260, 50260)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instructor.word2idx_dict), len(instructor.idx2word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6880250573158264"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructor.adv_train_generator(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6984397768974304"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructor.adv_train_discriminator(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Adversarial Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g_loss: 0.6940, d_loss: 0.6815, temperature: 1.0000:   0%| | 0/100 [14:35<?, ?i"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-969fcea89044>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minstructor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\diploma\\github\\dpl\\models\\instructor_LSTM.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m                 'g_loss: %.4f, d_loss: %.4f, temperature: %.4f' % (g_loss, d_loss, self.gen.temperature))\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# TEST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcal_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             wandb.log({'g_loss': g_loss, 'd_loss': d_loss,\n\u001b[0;32m     48\u001b[0m                        \u001b[1;34m'BLEU_2'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BLEU_3'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BLEU_4'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BLEU_5'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\diploma\\github\\dpl\\models\\instructor.py\u001b[0m in \u001b[0;36mcal_metrics\u001b[1;34m(self, fmt_str)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mfmt_str\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mformat\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \"\"\"\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[1;31m# Prepare data for evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0meval_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\diploma\\github\\dpl\\models\\RelGAN_G.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, num_samples, batch_size, one_hot, start_letter)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m                 \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m                 \u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\diploma\\github\\dpl\\models\\RelGAN_G.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, inp, hidden)\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[0memb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m         \u001b[0mgumbel_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_gumbel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm2out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[0mnext_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgumbel_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;31m# next_token_onehot = F.one_hot(next_token, cfg.vocab_size).float()  # not used yet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Interference\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Interference\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Interference\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1608\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1609\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1610\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1611\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "instructor._run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_ids_to_tokens\n",
    "# decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.dataloader import GANDataset, GenDataIter\n",
    "# from utils.preprocess import *\n",
    "SAMPLES_NUM = 10\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "eval_samples = instructor.gen.sample(SAMPLES_NUM, 4 * BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess import tensor_to_tokens\n",
    "gen_tokens = tensor_to_tokens(eval_samples, instructor.idx2word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tokens_transformer(filename, samples):\n",
    "    if cfg.tokenizator == 'GPT2':\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained('gpt2', unk_token='<unk>', eos_token='<pad>',\n",
    "                                                   pad_token='<pad>', bos_token='<start>')\n",
    "    elif cfg.tokenizator == 'BERT':  # TODO implement\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    texts = [tokenizer.decode(x) for x in samples]\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for sent in texts:\n",
    "            f.write(sent)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()+'dddd.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configuration as cfg\n",
    "save_tokens_transformer(path, eval_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ġoptimize', 'ĠLon', 'Cast', 'ĠSchiff', '--------------', 'boa', 'Ġbystanders', 'Ġnascent', 'Ġ503', 'Ġrental', 'Ġstarved', 'ĠReact', 'ĠSwe', 'Ġcontain', 'ĠFront', 'Ġmyst', 'ĠUzbek', 'ĠESA', 'mL', 'pers', 'Ġstandby', 'ĠSchn', 'ĠShotgun', 'ĠArsenal', 'Ġdonated', 'ĠSteps', 'Ġblessings', 'sounding', 'Ġsaving', 'lection', 'Ġnations', 'Human', 'Ġripping', 'Ġimportance', 'ĠSingle', 'Ġemission', 'False', 'ij', 'containing', 'acio', 'ĠEnc', '591', 'ĠBreast', 'hedon', 'tc', 'axe', 'iatrics', 'IRED', 'rider', 'ĠCalling']\n",
      "\n",
      "['Ġstall', 'Ġeru', 'ĠCly', 'Ġmelted', \"')\", 'Ġitching', 'Ġwarranties', 'éĩ', 'ĠExercise', 'Ġconditioning', 'ĠBaron', 'ĠGohan', 'ĠGREAT', 'verbs', 'ĠConst', 'ĠVT', 'Ġabandon', 'Ġindicated', 'ĠBars', 'Syn', 'ĠParent', 'arist', 'Ġconverting', 'ocaly', 'ĠHistorically', 'Ġblasts', 'Ġcapitalize', 'Ġgenerators', 'Ġnotwithstanding', 'Ġ:=', 'Ġnodd', 'ĠStay', 'Ġdrinkers', 'ĠBerg', 'ousing', 'Ġmemories', 'Ġcontrolled', 'Ġ342', 'rush', 'Ġbranding', 'ĠSPL', 'AGE', 'Ġcollegiate', 'Ġcompan', 'Ġpriceless', 'Ġur', 'Ġstringent', 'Ġ1934', 'Honestly', 'My']\n",
      "\n",
      "['Ġaffirmative', 'elope', 'Ġcubes', 'ĠMend', 'Ġeradicate', 'Ġtreatments', 'ĠSwed', \"'/\", 'Details', 'cin', 'Ġ\"%', 'fashion', 'Ġintoler', 'uders', 'ocrats', 'Ġfertility', '674', 'ĠIRC', 'achable', 'ĠIntake', 'ĠClarkson', 'azar', 'ĠRd', 'Ġtypically', 'anc', 'ight', 'ociation', 'ĠPsychiat', 'mast', '}}}', 'Ġlinemen', 'ge', 'wear', 'Ġ435', 'Ġsucc', 'settings', 'usual', 'Ġcontest', '49', 'Ġmuseum', 'ĠFailed', 'ĠFreedom', 'ĠDeadline', 'Ġembed', 'saf', 'AS', 'Ġ259', 'stretched', 'Ġsensit', 'Ġcaric']\n",
      "\n",
      "['adequ', 'guided', 'Ġexamines', 'Ġpresidents', 'ĠHes', 'Kevin', 'pretty', '420', '~', 'yan', 'Ġburner', 'ĠIsraeli', 'Ġcynicism', 'gat', 'Ġmimic', 'pillar', 'ĠâĻ', 'Ġ1916', 'Ġstepped', 'ensed', 'Ġburgl', 'å¤§', 'Ġthieves', '045', 'ĠWay', 'Ġpsyche', 'Ġbreakfast', 'Ġspecials', 'Ġpropri', 'Ġgroups', 'ĠBeetle', 'Inf', 'bable', 'Ġdecks', '442', 'Ġbrisk', '553', 'ĠPil', 'MP', 'Ġcontaminants', 'Ġ164', 'Ġmerc', 'Ġtalents', 'soever', '524', 'enting', 'ĠPoke', 'Ġsidewalk', 'Ġanecdote', 'obe']\n",
      "\n",
      "['ĠBirthday', 'RD', 'ĠCONTR', '278', 'Ġ320', 'Ġnarcissistic', 'ĠShal', 'ĠEli', 'Ġ2013', 'ye', 'arations', 'see', 'Ġgrades', 'ĠSophia', 'Ġglands', 'inho', 'coat', 'ĠGained', 'Led', 'Wil', 'Ġlest', 'Ġherpes', 'Ġastronauts', 'Four', 'Adapter', 'Ġmerch', 'Ġfish', 'Crunch', 'ĠTER', 'Ġautopsy', 'cens', 'ĠCHRIST', 'ĠRoberts', 'S', 'yton', 'Ġfert', 'ĠWI', 'Hum', 'abase', 'Ġmodify', 'ĠOrche', 'keepers', 'Ġmus', 'Ġ${', 'Ġacknowled', 'Ġfreshman', 'ĠCOURT', 'anks', 'Ġnuisance', 'Ġsearched']\n",
      "\n",
      "['Ġvet', 'Ġformulations', 'Ġrenegoti', 'Ġtoxicity', 'Ġsee', 'elvet', 'itizens', 'Ġput', 'ocolate', 'Ġassassins', 'Ġconsolid', 'Quotes', 'ĠInterstate', 'Ġcentrif', 'PN', 'Ġ43', 'ride', 'ĠAmir', 'ĠSalman', 'Ġalbeit', 'Ġcompressed', 'Ġ100', 'Ġmetallic', 'Notes', 'Ġlearns', 'ï¿½ï¿½ï¿½', 'ĠAdvice', 'ĠCot', 'ĠCanaver', 'Ġanalyst', 'fights', 'amation', 'Ġfoam', 'Exit', 'Ġ470', 'plex', 'riz', 'ĠRounds', 'heses', 'Ĥ¬', 'Ġdefence', 'favorite', 'rington', 'Ġreproduction', 'ois', 'ĠMont', 'Rat', 'Ġnap', 'Ax', 'ISION']\n",
      "\n",
      "['ĠZionist', 'Ġfavored', 'hate', 'Ġhotline', 'kes', 'Ġacet', 'ĠDocuments', 'ĠFired', 'Craft', 'iac', 'ĠIcar', 'Ġharshly', 'Ġmedd', 'Ġplight', 'Ġprimed', 'Ġthicker', 'ikk', 'Os', 'ournaments', 'Tex', '\"}],\"', 'ĠDistrict', 'Ġprophecy', 'Bl', 'ĠPRE', 'Ġtheat', 'ĠEnchant', 'Ġintervened', 'kar', 'hum', 'Ġisland', 'ĠDating', 'ĠBever', 'rather', '½', 'Ġpiv', 'Ġentitle', 'Ġpurchased', 'EA', 'Ġgou', 'Ġaccumulate', 'Ġquarterbacks', 'Ġdistant', 'European', 'Ġlobbyist', 'Ġdrip', 'Ġcatchy', 'ĠCommunication', 'ĠMorris', 'ĠCommon']\n",
      "\n",
      "['MED', 'ĠPT', 'Ġdisg', 'Ġfamilial', 'Ġorganis', 'ision', 'ised', 'internet', 'Ġendpoint', 'Ġcompensation', 'Ġlewd', 'ĠKad', 'Ġgeek', 'Ġfooth', 'Fore', 'Ġsitu', 'Ġdetention', 'ĠRanch', 'riors', 'CRIP', 'Ġhopped', 'Ġcostumes', 'ĠAI', 'Ġshipped', 'aws', 'Ġpushing', 'Ġrapt', 'ĠFleming', 'ĠXbox', 'ithmetic', 'anni', 'ban', 'ĠJon', 'Ġdepart', '.:', 'want', 'Ġpayment', 'Ġkicking', 'xxxx', 'ĠEconomic', 'ĠNeph', 'ĠSince', 'Ġparental', 'Ġinformative', 'Ġchipset', 'Ġbull', 'Ġpistols', 'TION', 'ĠBannon', 'Ġexclaim']\n",
      "\n",
      "['ĠMean', 'Ġengaged', 'ropri', 'talk', 'ĠAlfred', 'ĠNordic', 'Ġharassment', 'ĠDuke', 'ations', 'Ġreality', 'inav', 'Ġpromoter', 'Ġanalytic', 'Ġprior', 'ĠABOUT', 'Ġensl', 'ĠSUPPORT', 'Ġclosing', 'Ġscreenings', 'ĠSwanson', 'Ġ143', 'ĠVinyl', '15', 'ALE', 'iet', 'Ġprosecuting', 'Ġdialog', '?),', 'GROUP', 'Ġdeviations', 'Ġclosed', 'culosis', 'ĠCarr', 'Ġapproval', 'ĠRemain', 'Ġprayers', 'ĠMonthly', 'Ġpoliticians', 'Ġaverages', 'Ġthyroid', 'etti', 'productive', 'Ġdoctor', 'Ġpassions', 'Ġimag', 'CN', 'Ġapplied', 'ĠNotice', 'Limited', 'BLIC']\n",
      "\n",
      "['Done', 'Ġwonder', 'ĠShot', 'iano', 'ĠBAL', 'Ġcircumstance', 'boarding', 'Ġtele', 'Ġcampus', 'Brow', 'ĠDefensive', 'ĠBird', 'ĠAAA', 'obby', 'Ġgubernatorial', 'Ġchallenge', 'Ġdup', 'aghd', 'Ġreinvent', 'ĠDefinitely', 'Flying', 'Ġof', 'ady', 'ĠBasin', 'doi', 'ĠInt', 'ĠMalaysian', 'ĠTak', 'cules', 'ĠKap', 'eping', 'Ġmarker', 'Ġheal', 'ĠPST', 'Ġbarn', 'early', 'tta', 'Ġsizing', 'Ġparticipation', 'Ġneoliberal', 'ĠÃĸ', 'GB', 'ĠUnleashed', 'ĠAcceler', 'Ko', 'Ġbye', 'Ġlocation', 'Ġchoice', 'Ġvaccination', 'ller']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in gen_tokens:\n",
    "    print(el)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
