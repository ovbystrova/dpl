{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_and_GPT2.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "usVVTHtW15e4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install transformers\n",
        "# !pip install --upgrade wandb\n",
        "# !wandb login <>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N3o_SvM2JtM",
        "colab_type": "code",
        "outputId": "45a81184-4ca4-41bf-dc6a-a36eb44b1d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import wandb\n",
        "wandb.init(project=\"dpl\", name='bert_')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext  import data\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/2ispany3/dpl\" target=\"_blank\">https://app.wandb.ai/2ispany3/dpl</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/2ispany3/dpl/runs/3bmc3920\" target=\"_blank\">https://app.wandb.ai/2ispany3/dpl/runs/3bmc3920</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy13wmKU2UUZ",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsAZ3v3a2WUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def open_file(file):\n",
        "    with open(file, 'r', encoding='utf-8') as f:\n",
        "        text_list = [line for line in f.readlines()]\n",
        "    return text_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6LszcTU2Y-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uncomment if google colab:\n",
        "import os \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/')\n",
        "\n",
        "fake = open_file(\"data/fake.txt\")\n",
        "real = open_file(\"data/real.txt\")\n",
        "df = pd.read_csv(\"data/dataset.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORbfywBO2e7U",
        "colab_type": "code",
        "outputId": "e6eb6eaf-6e1b-4d90-b265-82f419e013d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "print(len(fake), len(real), df.shape)\n",
        "print(fake[:2])\n",
        "print(real[:2])\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37366 37366 (74730, 2)\n",
            "['Spinach has terrorized generations of veggie-phobic kids, and many grownups don\\'t much like it, either..\"I think it\\'s a little bit of a shock to see that he\\'s been able to do this,\"\\n', 'All day, every day, Cheryl Bernstein thanks her 16-month-old son. the boy is a little boy.\\n']\n",
            "[\"Spinach has terrorized generations of veggie-phobic kids, and many grownups don't much like it, either. But when it's combined with seasonings and feta cheese and wrapped in a golden crisp phyllo dough crust, even those who despise Popeye's Â\\xadfavorite food ask for seconds.\\n\", 'All day, every day, Cheryl Bernstein thanks her 16-month-old son. \"I gave life to Reid, but he gave me life - a reason to get clean and go on,\" she said yesterday after graduating from the Manhattan Family Treatment Court program.\\n']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Is a skull from Petralona Cave, Greece, the ol...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Network Readiness Index published by the W...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Now they've got Justin Bieber too. He was just...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NOGALES, Arizona — Jessica Elizabeth Orellana ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Many companies that are using cloud computing ...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label\n",
              "0  Is a skull from Petralona Cave, Greece, the ol...  real\n",
              "1  The Network Readiness Index published by the W...  fake\n",
              "2  Now they've got Justin Bieber too. He was just...  real\n",
              "3  NOGALES, Arizona — Jessica Elizabeth Orellana ...  real\n",
              "4  Many companies that are using cloud computing ...  fake"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBd8G7RWfDaM",
        "colab_type": "text"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLfcQZOv2tpF",
        "colab_type": "code",
        "outputId": "87d82b3f-927b-45cd-a596-02c0dbf4a6d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pretrained_weights = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\n",
        "model = BertForSequenceClassification.from_pretrained(pretrained_weights)\n",
        "\n",
        "embeddings_pretrained = model.get_input_embeddings()\n",
        "embeddings_pretrained"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(30522, 768, padding_idx=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDiCVgZv68j1",
        "colab_type": "code",
        "outputId": "1df1c13b-098a-4054-b76f-81b21ce5cbb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def tokenize(text, tokenizer=tokenizer):\n",
        "    return tokenizer.encode(text)\n",
        "\n",
        "MAX_VOCAB_SIZE = 50000\n",
        "classes={'fake': 0, 'real': 1}\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, include_lengths=False, batch_first=True, tokenize=tokenize, \n",
        "             pad_first=True, lower=False) \n",
        "LABEL = data.LabelField(dtype=torch.long, use_vocab=True, preprocessing=lambda x: classes[x])\n",
        "\n",
        "dataset = data.TabularDataset('data/dataset.csv', \n",
        "                                format='csv', fields=[('text', TEXT), ('label',LABEL),], \n",
        "                                skip_header=True)\n",
        "\n",
        "TEXT.build_vocab(dataset,  max_size=MAX_VOCAB_SIZE, min_freq=2)\n",
        "LABEL.build_vocab(dataset)\n",
        "vocab = TEXT.vocab\n",
        "print('Vocab size:', len(TEXT.vocab.itos))\n",
        "\n",
        "train, test = dataset.split(0.8, stratified=True)\n",
        "train, valid = train.split(0.8, stratified=True)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 24776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK1bURO79gB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "num_epochs = 10\n",
        "\n",
        "model.to(device)\n",
        "wandb.watch(model)\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train, valid, test),\n",
        "    batch_sizes=(batch_size, batch_size, batch_size),\n",
        "    shuffle=True,\n",
        "    device=device,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    sort_within_batch=True,\n",
        ")\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki_52I0tPOAr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "640d6c50-975f-4058-dfe9-3b04a8665b05"
      },
      "source": [
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(params)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "109483778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n8YI__5r0ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for p in model.named_parameters():\n",
        "#     print(p[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my9-_OzAQWyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for p in model.bert.encoder.parameters(): \n",
        "    p.requires_grad = False \n",
        "\n",
        "for p in model.bert.pooler.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "for p in model.bert.embeddings.parameters(): \n",
        "    p.requires_grad = False \n",
        "\n",
        "# for p in model.bert.encoder.layer[-1].parameters():\n",
        "#     p.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_JojorsPkMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9b34338-4b8e-4210-a5c2-d02be4d0490d"
      },
      "source": [
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(params)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhqydt55-IO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_score(preds, y):\n",
        "    preds = (preds == y).float()\n",
        "    accuracy = preds.sum() / len(preds)\n",
        "    return accuracy.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eXTNk5I-Loq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _train_epoch(model, iterator, optimizer, curr_epoch):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0\n",
        "    losses = []\n",
        "    train_acc = []\n",
        "\n",
        "    n_batches = len(iterator)    \n",
        "    iterator = tqdm_notebook(iterator, total=n_batches, desc='epoch %d' % (curr_epoch), leave=True)\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        x = batch.text\n",
        "        y = batch.label\n",
        "        outputs = model(x, labels=y)\n",
        "        loss, logits = outputs[:2]\n",
        "        _, preds = torch.max(F.softmax(logits, dim=1),1)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
        "        optimizer.step()        \n",
        "        curr_loss = loss.data.detach().item()\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        acc = accuracy_score(preds, y)\n",
        "        train_acc.append(acc)\n",
        "        iterator.set_postfix(loss='%.5f' % curr_loss, acc='%.5f' % acc)\n",
        "\n",
        "        wandb.log({\n",
        "        \"Train Accuracy\": np.mean(train_acc),\n",
        "        \"Train Loss\": curr_loss})\n",
        "    return curr_loss, losses, train_acc\n",
        "\n",
        "def _test_epoch(model, iterator):\n",
        "    model.eval()    \n",
        "    epoch_loss = 0\n",
        "    losses = []\n",
        "    test_acc = []\n",
        "\n",
        "    n_batches = len(iterator)\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            x = batch.text\n",
        "            y = batch.label\n",
        "            outputs = model(x, labels=y)\n",
        "            loss, logits = outputs[:2]\n",
        "            _, preds = torch.max(F.softmax(logits, dim=1),1)\n",
        "            test_acc.append(accuracy_score(preds, y))\n",
        "            losses.append(loss.item())\n",
        "            epoch_loss += loss.data.item()\n",
        "    \n",
        "    wandb.log({\n",
        "        \"Valid Accuracy\": np.mean(test_acc),\n",
        "        \"Valid Loss\": epoch_loss/n_batches})\n",
        "    \n",
        "    return epoch_loss / n_batches, losses, test_acc\n",
        "\n",
        "def nn_train(model, train_iterator, valid_iterator, optimizer, n_epochs=20, early_stopping=0):\n",
        "\n",
        "    prev_loss = 10500\n",
        "    es_epochs = 0\n",
        "    best_epoch = None\n",
        "    history = pd.DataFrame()\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    train_accs = []\n",
        "    valid_accs = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, epoch_tl, train_acc = _train_epoch(model, train_iterator, optimizer, epoch)\n",
        "        valid_loss,  epoch_vl, valid_acc = _test_epoch(model, valid_iterator)\n",
        "\n",
        "        train_losses.extend(epoch_tl)\n",
        "        valid_losses.extend(epoch_vl)\n",
        "        train_accs.extend(train_acc)\n",
        "        valid_accs.extend(valid_acc)\n",
        "\n",
        "        print('validation loss %.5f' % valid_loss, 'validation accuracy  %.5f' % np.mean(valid_accs))\n",
        "\n",
        "        record = {'epoch': epoch, 'train_loss': train_loss, 'valid_loss': valid_loss, 'train_acc': np.mean(train_accs), 'valid_acc':np.mean(valid_accs)}\n",
        "        history = history.append(record, ignore_index=True)\n",
        "\n",
        "        if early_stopping > 0:\n",
        "            if valid_loss > prev_loss:\n",
        "                es_epochs += 1\n",
        "            else:\n",
        "                es_epochs = 0\n",
        "            if es_epochs >= early_stopping:\n",
        "                best_epoch = history[history.valid_loss == history.valid_loss.min()].iloc[0]\n",
        "                print('Early stopping! best epoch: %d val %.5f' % (best_epoch['epoch'], best_epoch['valid_loss']))\n",
        "                break\n",
        "            prev_loss = min(prev_loss, valid_loss)\n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Cf94Ac-Sq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = nn_train(model, train_iterator, valid_iterator,\n",
        "                   optimizer, n_epochs=1, early_stopping=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p3DYj2i-T8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, test_iterator):\n",
        "    test_acc = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for item in test_iterator:\n",
        "            x = item.text\n",
        "            y = item.label\n",
        "            outputs = model(x, labels=y)\n",
        "            loss, logits = outputs[:2]\n",
        "            _, preds = torch.max(F.softmax(logits, dim=1),1)\n",
        "            test_acc.append(accuracy_score(preds, y))\n",
        "    test_acc = np.mean(test_acc) \n",
        "    return np.mean(test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svqm_rUW_ntI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy = test_model(model, test_iterator)\n",
        "print('Test accuracy: {}'.format(np.mean(test_accuracy)))\n",
        "\n",
        "wandb.log({\n",
        "        \"Test Accuracy\": test_accuracy})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ19N9HminoU",
        "colab_type": "code",
        "outputId": "c3b95a1f-b246-4995-d7e0-08bc99063d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wandb.save('bert.h5')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    }
  ]
}