{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3DsNgoSGPXK1"
   },
   "outputs": [],
   "source": [
    "# !pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vhwpv1fZN713"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import eli5\n",
    "from eli5.lime import TextExplainer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, GPT2Model, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Заменить на данные из итогового датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CE0rGSAmP7ef"
   },
   "outputs": [],
   "source": [
    "def open_file(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        text_list = [line for line in f.readlines()]\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wCz47nSkP8Sw"
   },
   "outputs": [],
   "source": [
    "fake = open_file(\"data/fake.txt\")\n",
    "real = open_file(\"data/real.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhH3DemKQe8w"
   },
   "outputs": [],
   "source": [
    "pretrained_weights = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_weights)\n",
    "model = GPT2Model.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wFTN1IKiQh9x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_pretrained = model.get_input_embeddings()\n",
    "embeddings_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6CSWqJeaQj1F"
   },
   "outputs": [],
   "source": [
    "EMBEDDINGS_DIM = embeddings_pretrained.embedding_dim\n",
    "VOCAB_SIZE = embeddings_pretrained.num_embeddings\n",
    "EMB_PRETRAINED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WSVrbHi9QZfN"
   },
   "outputs": [],
   "source": [
    "def tokenize(text, tokenizer=tokenizer):\n",
    "    return tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7cQtZcezQROA"
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, \n",
    "                 emb_pretrained, embeddings):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.emb_pretrained = emb_pretrained\n",
    "        self.embedding =  embeddings if self.emb_pretrained else nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.LSTM(input_size=embed_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           bidirectional=True,\n",
    "                           batch_first=True,\n",
    "                          )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size * 2 *2, 1)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "           \n",
    "        _, (hidden, cell) = self.rnn(x)\n",
    "        \n",
    "        hidden = hidden.transpose(0,1)\n",
    "        cell = cell.transpose(0,1)\n",
    "        hidden = hidden.contiguous().view(hidden.size(0),-1)\n",
    "        cell = cell.contiguous().view(cell.size(0),-1)\n",
    "        x = torch.cat([hidden, cell], dim=1).squeeze(1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'tokenization/embeddings': 'gpt2',\n",
    "            'batch_size': 256,\n",
    "          'hidden_size' : 128,\n",
    "            'num_epochs': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pncyH6TBQo0k"
   },
   "outputs": [],
   "source": [
    "model = MyModel(VOCAB_SIZE,\n",
    "                embed_size=EMBEDDINGS_DIM,\n",
    "                hidden_size=config['hidden_size'],\n",
    "                emb_pretrained = EMB_PRETRAINED,\n",
    "                embeddings = embeddings_pretrained\n",
    "               )\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cToSBgZlPlfO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = torch.load('data/train.2.pth', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(results['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bsmv3wmlPinI"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        super(LSTMClassifier, self).__init__() \n",
    "        self.model = model\n",
    "        self.classes_ = (0,1)\n",
    "\n",
    "    def fit(self, X=None, y=None, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, texts):\n",
    "        \"\"\"\n",
    "        texts: list of texts\n",
    "        :return: ndarray n_texts x n_classes\n",
    "        \"\"\"\n",
    "    \n",
    "        ids = [tokenizer.encode(text) for text in texts]\n",
    "        \n",
    "        for ind, el in enumerate(ids):\n",
    "            if len(el) < len(ids[0]):\n",
    "                while len(el) < len(ids[0]):\n",
    "                    el.append(1)\n",
    "            if len(el) > len(ids[0]):\n",
    "                ids[ind] = el[:len(ids[0])]            \n",
    "        \n",
    "        tensor = torch.tensor(ids)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.model.forward(tensor)\n",
    "            print('logits',logits)\n",
    "        sigmoids = torch.softmax(logits, dim=-1)  # First predict the 'Real' prob\n",
    "        print('sigmoids', sigmoids)\n",
    "        print('round', torch.round(sigmoids))\n",
    "        opposite_class_prob = 1 - sigmoids  # Then calculate the 'Fake' prob\n",
    "        print('opposite', opposite_class_prob)\n",
    "        probs = torch.cat((sigmoids, opposite_class_prob), dim=-1)\n",
    "        \n",
    "        return probs.detach().numpy()\n",
    "\n",
    "    def predict(self, text):\n",
    "        return int(torch.round(self.predict_proba(text)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JATQFRAqPvK4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(model=MyModel(\n",
       "  (embedding): Embedding(50257, 768)\n",
       "  (rnn): LSTM(768, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_estimator = LSTMClassifier(model)\n",
    "model_estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6b9e0JFPyHg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits tensor([[0.0498]])\n",
      "sigmoids tensor([[0.5125]])\n",
      "opposite tensor([[0.4875]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5124597, 0.4875403]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_estimator.predict_proba([fake[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(model=MyModel(\n",
       "  (embedding): Embedding(50257, 768)\n",
       "  (rnn): LSTM(768, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_estimator = LSTMClassifier(model)\n",
    "model_estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits tensor([[-16.5015]])\n",
      "sigmoids tensor([[1.]])\n",
      "round tensor([[1.]])\n",
      "opposite tensor([[0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_estimator.predict_proba([real[-11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# help(TextExplainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(te.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7upEgvEgQFAs",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from IPython.display import display, HTML\n",
    "\n",
    "# for i in range(1, 51, 10):\n",
    "#     text_fake = fake[i]\n",
    "#     text_real = real[i]\n",
    "#     te = TextExplainer(random_state=42)\n",
    "#     print(model_estimator.predict_proba([text_fake]))\n",
    "#     te.fit(doc=text_fake, predict_proba=model_estimator.predict_proba)\n",
    "#     print('True label: Fake')\n",
    "#     display(te.show_prediction(target_names=['Fake','Real']))\n",
    "    \n",
    "#     print(model_estimator.predict_proba([text_real]))\n",
    "#     te.fit(doc=text_real, predict_proba=model_estimator.predict_proba)\n",
    "#     print('True label: Real')\n",
    "#     display(te.show_prediction(target_names=['Fake','Real']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AhjRWQtiQHw8"
   },
   "outputs": [],
   "source": [
    "text = real[44]\n",
    "text\n",
    "print(model_estimator.predict_proba([text]))\n",
    "te = TextExplainer(random_state=42)\n",
    "te.fit(doc=text, predict_proba=model_estimator.predict_proba)\n",
    "te.show_prediction(target_names=['Fake','Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Eli5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
