{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Making_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPsIoSZJ4Usq",
        "colab_type": "text"
      },
      "source": [
        "Cornel Newsroom summarization dataset (https://summari.es/) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8YLXVYZARYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PadfOYhtSSNG",
        "colab_type": "code",
        "outputId": "4594c94e-36da-4054-eaae-a1e2bf7a3f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from tqdm  import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "from nltk import tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWRkOHRH6jYT",
        "colab_type": "text"
      },
      "source": [
        "# Initial Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebAEq3iClUz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMr_uOTj4Yw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae71d27e-e8c2-4e25-97eb-a16adbe59aec"
      },
      "source": [
        "def clean_tqdm():\n",
        "    for instance in list(tqdm._instances): \n",
        "        tqdm._decr_instances(instance)\n",
        "\n",
        "for e in tqdm([1,2,3]):\n",
        "    pass\n",
        "\n",
        "def clean_data(text):\n",
        "    text = re.sub(r'\\<[^>]*\\>', '', text)\n",
        "    text = re.sub(r'\\\\n', ' ', text)\n",
        "    text = re.sub(r'&[a-z]{0,7};', ' ', text)\n",
        "    text = re.sub(r'\\s{2,10}', ' ', text)\n",
        "    text = re.sub(r'\\s{2,10}', ' ', text)\n",
        "    text = re.sub(r\"\\\\'\", r\"'\", text)\n",
        "    text = re.sub(r'\\\\x\\d{1,4}', '', text)\n",
        "    return text\n",
        "\n",
        "def get_sentences(data):\n",
        "    \"\"\"\n",
        "    splits texts into sentences\n",
        "    return: list of sentences to pass to gpt model \n",
        "            list of sentences to pass to classification model as real texts\n",
        "    \"\"\"\n",
        "    texts_gpt2 = []\n",
        "    texts_real = []\n",
        "\n",
        "    for text in data:\n",
        "        tokenized = tokenize.sent_tokenize(text)\n",
        "        if len(tokenized) >= 2 and len(tokenized[0].split(' ')) < 50:\n",
        "            texts_gpt2.append(tokenized[0])\n",
        "            texts_real.append(' '.join(tokenized[:2]))\n",
        "    assert len(texts_real) == len(texts_gpt2)\n",
        "    return texts_gpt2, texts_real"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13079.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viLUYm58SqZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/train-stats.jsonl', 'r') as json_file:\n",
        "        json_list = list(json_file)[70001:]\n",
        "        \n",
        "data = []\n",
        "for json_str in json_list:\n",
        "        result = json.loads(json_str)\n",
        "        data.append(clean_data(result['text']))\n",
        "del json_list\n",
        "\n",
        "texts_gpt2, texts_r = get_sentences(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMzhFVfu6Z85",
        "colab_type": "code",
        "outputId": "fb207903-242a-4384-97d1-a483701a1dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Total amount of texts: {}'.format(len(texts_gpt2)))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total amount of texts: 878615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnY3yDUm48yu",
        "colab_type": "code",
        "outputId": "adb89c05-6160-42f5-9a61-5092f16f72ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "texts_gpt2[:3], texts_r[:3]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Hewlett-Packard CEO Meg Whitman said Wednesday the company embarked on another round of layoffs in part because the technology market is changing so rapidly.',\n",
              "  \"It's worth noting that some of these stocks, like telecom company Frontier Communications and oil and gas driller Helmerich & Payne, have sky-high valuations because earnings expectations are nearly nil; the story for oil exploration and production company ConocoPhillips is similar.\",\n",
              "  \"TAIPEI, Sept 10 (Reuters) - Computer maker Dell Inc will invest $125 billion in China over the next five years, its chief executive said on Thursday, as the company continues to expand in the world's second-largest economy.\"],\n",
              " ['Hewlett-Packard CEO Meg Whitman said Wednesday the company embarked on another round of layoffs in part because the technology market is changing so rapidly. \"It\\'s remarkable what\\'s happening to our services business.',\n",
              "  \"It's worth noting that some of these stocks, like telecom company Frontier Communications and oil and gas driller Helmerich & Payne, have sky-high valuations because earnings expectations are nearly nil; the story for oil exploration and production company ConocoPhillips is similar. Energy names Marathon Oil and Murphy Oil are actually expected to report losses rather than profits, which is why they don't have price-to-earnings ratios at all.\",\n",
              "  \"TAIPEI, Sept 10 (Reuters) - Computer maker Dell Inc will invest $125 billion in China over the next five years, its chief executive said on Thursday, as the company continues to expand in the world's second-largest economy. The world's third-largest maker of personal computers said the investment would contribute about $175 billion to imports and exports, sustaining more than one million jobs in China.\"])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI4qBx5lGNAg",
        "colab_type": "code",
        "outputId": "1ac2072f-b310-4ae1-b495-d1828b45fd22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "texts_gpt2[-3:], texts_r[-3:]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Elizabeth Taylor has White Diamonds.',\n",
              "  'BALTIMORE, May 18 -- A disease believed to be equine herpes virus has swept through the barn area at Churchill Downs, site of the Kentucky Derby, leading to the death of two horses and the placement of a quarantine on three barns.',\n",
              "  'Columnist Michelle Singletary was online to field questions about everything from retirement planning to protecting your credit rating.'],\n",
              " ['Elizabeth Taylor has White Diamonds. Coco Chanel had Chanel No.',\n",
              "  'BALTIMORE, May 18 -- A disease believed to be equine herpes virus has swept through the barn area at Churchill Downs, site of the Kentucky Derby, leading to the death of two horses and the placement of a quarantine on three barns. The outbreak of the rare neurological virus, which can cause symptoms ranging from mild fever and upper respiratory infection to paralysis, has led to the scratching of three horses scheduled to run this weekend at Pimlico in major stakes races.',\n",
              "  'Columnist Michelle Singletary was online to field questions about everything from retirement planning to protecting your credit rating. Michelle Singletary: Welcome.'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRjTRjYt6nPs",
        "colab_type": "text"
      },
      "source": [
        "# Generation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsC593ip47Ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 50\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', pad_token='<pad>', max_length=500)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.to(device);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxTUUmTs47J8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_fake(texts, sampling_type, tokenizer=tokenizer, model=model):\n",
        "    \"\"\"\n",
        "    Generates texts depending on sampling_type. \n",
        "    sampling type: tuple (sampling_type : value)\n",
        "    return: list of fake texts\n",
        "    \"\"\"\n",
        "    fake = []\n",
        "    samplings = []\n",
        "\n",
        "    for el in tqdm(texts):    \n",
        "        sent = generate_sentence(el, model, tokenizer, sampling_type)            \n",
        "        sent = re.sub(r'\\n', ' ', sent)\n",
        "        fake.append(sent)\n",
        "        samplings.append(sampling_type[0])        \n",
        "    return fake, samplings\n",
        "\n",
        "def generate_sentence(sentence, model, tokenizer, sampling_type, max_length=MAX_LENGTH):    \n",
        "    \"\"\"\n",
        "    Generates sentence depending on sampling_type\n",
        "    return: str\n",
        "    \"\"\"\n",
        "    eos = tokenizer.encode('.?!...! ?')\n",
        "    context = torch.tensor([tokenizer.encode(sentence)][:500]).to(device)\n",
        "    max_length += context.size()[-1]\n",
        "    \n",
        "    if sampling_type[0] == 'beam_search':\n",
        "        outputs = model.generate(input_ids=context, max_length=max_length,\n",
        "                                 do_sample=True, num_beams=sampling_type[1],\n",
        "                                 pad_token_id=tokenizer.pad_token_id,\n",
        "                                 repetition_penalty=2.3)\n",
        "    elif sampling_type[0] == 'temperature':\n",
        "        outputs = model.generate(input_ids=context, max_length=max_length,\n",
        "                                 do_sample=True, temperature=sampling_type[1],\n",
        "                                 pad_token_id=tokenizer.pad_token_id)\n",
        "    elif sampling_type[0] == 'top_k':\n",
        "        outputs = model.generate(input_ids=context, max_length=max_length,\n",
        "                                 do_sample=True, temperature=sampling_type[1],\n",
        "                                 pad_token_id=tokenizer.pad_token_id)\n",
        "    elif sampling_type[0] == 'nucleus':\n",
        "        outputs = model.generate(input_ids=context, max_length=max_length,\n",
        "                                 do_sample=True, top_p=sampling_type[1],\n",
        "                                 pad_token_id=tokenizer.pad_token_id)\n",
        "    else:  # Argmax otherwise\n",
        "        outputs = model.generate(input_ids=context, max_length=max_length, do_sample=False,\n",
        "                                 pad_token_id=tokenizer.pad_token_id)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def df_checkpoint(texts_fake, texts_real, samplings):\n",
        "    \"\"\"\n",
        "    creates pandas DataFrame with texts (both real and fake) and sampling type\n",
        "    saves df to google drive and working directory\n",
        "    return: pandas DataFrame\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(columns=['text', 'label', 'sampling'])\n",
        "    df['text'] = texts_fake + texts_real\n",
        "    df['label'] = ['fake']* len(texts_fake) + ['real']* len(texts_real)\n",
        "    df['sampling'] = samplings  + ['No sampling'] * len(texts_real)\n",
        "    df.to_csv('dataset.csv', index=False)\n",
        "    df.to_csv('/content/drive/My Drive/dpl_dataset.csv', index=False)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32aa6iZlV0_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If something crashes\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/dpl_dataset.csv')\n",
        "samplings = list(df[df['sampling'] != 'No sampling']['sampling'])\n",
        "texts_fake = list(df[df['label'] == 'fake']['text'])\n",
        "texts_real = list(df[df['label'] == 'real']['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_vV6stRUSkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c1e19b0-f715-48a6-94d2-a67c8448914e"
      },
      "source": [
        "len(texts_fake), len(texts_real), len(samplings)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 70000, 70000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlCSXIa4xs2Y",
        "colab_type": "text"
      },
      "source": [
        "So far I didn't use beam_search as it takes a lot of time to generate texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30fBTzez466O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "c2ddee4c-b549-4965-a41d-0d2c50f41e6b"
      },
      "source": [
        "n = 10000  # Number of texts to generate for every sampling type (70k total for each sampling type)\n",
        "# sampling_types = [('temperature', 0.9), ('temperature', 0.8), ('top_k', 20), ('top_k', 100), ('nucleus', 0.9), ('nucleus', 0.8), ('argmax', 23), ('beam_search', 3), ('beam_search',5)]\n",
        "# texts_fake = []\n",
        "# texts_real = []\n",
        "# samplings = []\n",
        "sampling_types = [('temperature', 0.9), ('temperature', 0.8), ('top_k', 20), ('top_k', 100), ('nucleus', 0.9), ('nucleus', 0.8), ('argmax', 23)]\n",
        "\n",
        "\n",
        "for ind, sampling_type in enumerate(sampling_types):\n",
        "    clean_tqdm()\n",
        "    print('Starting generation for {}'.format(sampling_type))\n",
        "    fake, sampling  = generate_fake(texts_gpt2[ind*n:ind*n+n], sampling_type, tokenizer=tokenizer,model=model)\n",
        "    texts_fake.extend(fake)\n",
        "    samplings.extend(sampling)\n",
        "    texts_real.extend(texts_r[ind*n:ind*n+n])\n",
        "\n",
        "    df = df_checkpoint(texts_fake, texts_real, samplings)\n",
        "    print('DataFrame saved')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 69/10000 [26:57<64:40:12, 23.44s/it]\n",
            "  0%|          | 0/10000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting generation for ('temperature', 0.9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [1:35:01<00:00,  1.75it/s]\n",
            "  0%|          | 0/10000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DataFrame saved\n",
            "Starting generation for ('temperature', 0.8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 9748/10000 [1:33:29<02:09,  1.94it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5-ZRWdlK1xj",
        "colab_type": "code",
        "outputId": "0f3bb50c-aec7-47c2-bfad-58362d1ffb74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sampling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAMBURG, Germany, June 3  As he left the socc...</td>\n",
              "      <td>fake</td>\n",
              "      <td>temperature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WASHINGTON, Dec. 23 - The National Security Ag...</td>\n",
              "      <td>fake</td>\n",
              "      <td>temperature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IF outsized executive pay has indeed become a ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>temperature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BY A.J. Miller, Jr.  The three men will make t...</td>\n",
              "      <td>fake</td>\n",
              "      <td>temperature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Spinach has terrorized generations of veggie-p...</td>\n",
              "      <td>fake</td>\n",
              "      <td>temperature</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label     sampling\n",
              "0  HAMBURG, Germany, June 3  As he left the socc...  fake  temperature\n",
              "1  WASHINGTON, Dec. 23 - The National Security Ag...  fake  temperature\n",
              "2  IF outsized executive pay has indeed become a ...  fake  temperature\n",
              "3  BY A.J. Miller, Jr.  The three men will make t...  fake  temperature\n",
              "4  Spinach has terrorized generations of veggie-p...  fake  temperature"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_OcY9bBK2v9",
        "colab_type": "code",
        "outputId": "4528e199-e6ba-4df7-ceee-7f504bb154c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sampling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>WASHINGTON, July 11— Barred by a recent Suprem...</td>\n",
              "      <td>real</td>\n",
              "      <td>No sampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>WASHINGTON, Sept. 12— Justice Department offic...</td>\n",
              "      <td>real</td>\n",
              "      <td>No sampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>The army of prisoners grows at an alarming pac...</td>\n",
              "      <td>real</td>\n",
              "      <td>No sampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>Things are really jumping at the Queens Museum...</td>\n",
              "      <td>real</td>\n",
              "      <td>No sampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>Now that I am an ordinary citizen again, permi...</td>\n",
              "      <td>real</td>\n",
              "      <td>No sampling</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text label     sampling\n",
              "59995  WASHINGTON, July 11— Barred by a recent Suprem...  real  No sampling\n",
              "59996  WASHINGTON, Sept. 12— Justice Department offic...  real  No sampling\n",
              "59997  The army of prisoners grows at an alarming pac...  real  No sampling\n",
              "59998  Things are really jumping at the Queens Museum...  real  No sampling\n",
              "59999  Now that I am an ordinary citizen again, permi...  real  No sampling"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqbHye43IdEF",
        "colab_type": "code",
        "outputId": "f9e7e24d-7cac-4ca7-c371-330d5b2e4e15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "assert len(texts_fake) == len(texts_real)\n",
        "texts_fake[:5], texts_real[:5]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([\"HAMBURG, Germany, June 3 \\x97 As he left the soccer field after a club match in the eastern German city of Halle on March 25, the Nigerian forward Adebowale Ogungbure was spit upon, jeered with racial remarks and mocked with monkey noises. The incident, which took place in front of the national team's training facility in Dortmund, Germany, the day after the World Cup, drew national attention to the country's military culture and practices. More than 1,400 protesters took to the streets of\",\n",
              "  'WASHINGTON, Dec. 23 - The National Security Agency has traced and analyzed large volumes of telephone and Internet communications flowing into and out of the United States as part of the eavesdropping program that President Bush approved after the Sept. 11, 2001, attacks to hunt for evidence of terrorist activity, according to current and former government officials.  In addition, the National Security Agency has collected hundreds of millions of telephone and wire communications during the three years that the NSA has been conducting the investigation into alleged spying in the United States and abroad.  The NSA, the Defense Department and',\n",
              "  \"IF outsized executive pay has indeed become a source of outrage to American shareholders, then the contest this week between Pfizer Inc.'s investors and its board could prove the most compelling of the year.  Pfizer has been the target of several lawsuits over its drug development. In 2011 and 2012, for instance, it accused the FDA of ordering new approval that would reduce profits from Pfizer that the company could use to pay off the company\",\n",
              "  'BY A.J. Miller, Jr.  The three men will make their first appearance Saturday in the NCAA Division II Champions Classic, a series between Washington and Connecticut. And as for those who never got a chance to see this series when it first started, at least',\n",
              "  'Spinach has terrorized generations of veggie-phobic kids, and many grownups don\\'t much like it, either. With so many options, they sometimes turn for help. There\\'s this \"help food idea,\" for example, that\\'s like cooking up your own pasta to impress an adorable mom to tell her you\\'ve had it for three years. But the truth is'],\n",
              " ['HAMBURG, Germany, June 3 \\x97 As he left the soccer field after a club match in the eastern German city of Halle on March 25, the Nigerian forward Adebowale Ogungbure was spit upon, jeered with racial remarks and mocked with monkey noises. In rebuke, he placed two fingers under his nose to simulate a Hitler mustache and thrust his arm in a Nazi salute.',\n",
              "  'WASHINGTON, Dec. 23 - The National Security Agency has traced and analyzed large volumes of telephone and Internet communications flowing into and out of the United States as part of the eavesdropping program that President Bush approved after the Sept. 11, 2001, attacks to hunt for evidence of terrorist activity, according to current and former government officials. The volume of information harvested from telecommunication data and voice networks, without court-approved warrants, is much larger than the White House has acknowledged, the officials said.',\n",
              "  \"IF outsized executive pay has indeed become a source of outrage to American shareholders, then the contest this week between Pfizer Inc.'s investors and its board could prove the most compelling of the year. The battle lines have been drawn between Pfizer's owners and managers, who will assemble on Thursday at the annual shareholder meeting in Lincoln, Neb., at the Cornhusker Marriott hotel.\",\n",
              "  \"BY A.J. BENZA & MICHAEL LEWITTES If Simon Rex looks a little familiar, it may not have anything to do with his gig as an MTV veejay or his ads for Levi's and Tommy Hilfiger.\",\n",
              "  \"Spinach has terrorized generations of veggie-phobic kids, and many grownups don't much like it, either. But when it's combined with seasonings and feta cheese and wrapped in a golden crisp phyllo dough crust, even those who despise Popeye's Â\\xadfavorite food ask for seconds.\"])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}