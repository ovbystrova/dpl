{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataGener_Class.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLoMtRBPnLS8",
        "colab_type": "text"
      },
      "source": [
        "[Тут](https://colab.research.google.com/drive/1EpJkZLzM0v4c7A3O9XWtXds1_7xAreZx) весь оставшийся мусор по  подготовке датасетов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkgCFI7sR75B",
        "colab_type": "text"
      },
      "source": [
        "Пока: \n",
        "\n",
        "\n",
        "*   Каждые 10к датасета дают прибавление в accuracy (20к - 0.81; 70к - 0.87)\n",
        "*   То, что выше - это получается на первых 2-3 эпохах, дальше модель переобучается. \n",
        "*   Если убрать стопслова из датасета на 50к записей, то результаты хуже (0.8 acc)\n",
        "* Добавила регуляризацию: acc = 0.882 на пяти эпохах\n",
        "\n",
        "Что делаю сейчас: \n",
        "\n",
        "\n",
        "*   Пинаю писюны\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdzzYVxhqrBc",
        "colab_type": "code",
        "outputId": "e831f3cf-e7c9-4fc7-f8fc-2f57450e616a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#!pip install transformers\n",
        "!pip install tokenizers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.6/dist-packages (0.0.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKunajrGYutV",
        "colab_type": "code",
        "outputId": "8997b173-5ec5-4467-d0ba-460c9f676cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.10)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLkRnCh-mCEB",
        "colab_type": "code",
        "outputId": "12411b35-977f-4fb1-fcbe-81690f9a34d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "from spacy.symbols import ORTH\n",
        "import re\n",
        "import json\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.metrics import accuracy_score\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "\n",
        "import torch\n",
        "from torchtext.data import Field, LabelField, BucketIterator, TabularDataset, Iterator, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "#from tokenizers import SentencePieceBPETokenizer\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "#from tokenizers import SentencePieceBPETokenizer\n",
        "\n",
        "\n",
        "LENGTH = 10000\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "import nltk\n",
        "from nltk import tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "#spacy_en = spacy.load('en')\n",
        "#spacy_en.tokenizer.add_special_case(\"don't\", [{ORTH: \"do\"}, {ORTH: \"not\"}])\n",
        "#spacy_en.tokenizer.add_special_case(\"didn't\", [{ORTH: \"did\"}, {ORTH: \"not\"}]) #adding special case so that tokenizer(\"\"\"don't\"\"\") != 'do'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO1Y0kkXZAYu",
        "colab_type": "code",
        "outputId": "92c31ae9-97f2-43da-e049-a4d7b0d3f0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "tokenizer = SentencePieceBPETokenizer()\n",
        "tokenizer.train(['/content/wiki_train.txt', '/content/wiki_valid.txt'], special_tokens=['<eos>', '<unk>', '<start>'], vocab_size=30000)\n",
        "tokenizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-40f3d9416a10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentencePieceBPETokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'/content/wiki_train.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/wiki_valid.txt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<unk>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<start>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SentencePieceBPETokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Iz4rb52zW8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(text):\n",
        "    text = re.sub(r'\\<[^>]*\\>', '', text)\n",
        "    text = re.sub(r'\\<[^>]*\\>', '', text)\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'&[a-z]{0,7};', ' ', text)\n",
        "    text = re.sub(r'\\s{2,10}', ' ', text)\n",
        "    text = re.sub(r'\\s{2,10}', ' ', text)\n",
        "    text = re.sub('\\\\x\\d{1,4}', '', text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxjzcvpB0NKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_first(text): # to gpt2\n",
        "    return tokenize.sent_tokenize(text)[0]\n",
        "\n",
        "def sent_splitter(text): # to classification model\n",
        "    return ' '.join(tokenize.sent_tokenize(text)[:2])\n",
        "\n",
        "def tokenizer(text):\n",
        "    pass\n",
        "    #return [tok.lemma_ for tok in spacy_en.tokenizer(text) if tok.text.isalpha()]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBkHZ4NykdaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def open_file(file):\n",
        "    with open(file, 'r', encoding='utf-8') as f:\n",
        "        fake = [line for line in f.readlines()]\n",
        "    return fake"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLs3QxlMx_YL",
        "colab_type": "text"
      },
      "source": [
        "# Process Original Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SRA6pwPyBuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "idd = '1h_kUrWbKvZR0iRms8zKMUJO5zq9wbIXW' #Newsroom\n",
        "downloaded_ = drive.CreateFile({'id':idd}) \n",
        "downloaded_.GetContentFile('train.jsonl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKOzoQ7ryY4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initial(file, start_idx=0):\n",
        "    \n",
        "    with open(file, 'r') as json_file:\n",
        "        json_list = list(json_file)[start_idx:start_idx+LENGTH]\n",
        "    \n",
        "    data = []\n",
        "    for json_str in json_list:\n",
        "        result = json.loads(json_str)\n",
        "        data.append(result['text'])\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    df['text'] = data\n",
        "    df['label'] = ['real'] * len(data)\n",
        "    df['text'] = df['text'].apply(clean_data)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNH4otsEz2Cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_df(df):\n",
        "\n",
        "    text_gpt2 = list(df['text'].apply(sent_first))[:LENGTH]\n",
        "    df.text  = df['text'].apply(sent_splitter)\n",
        "\n",
        "    return text_gpt2, df "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ0ksJpL5wkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = initial('train.jsonl', start_idx=0) #Выгружаю пачками по 10к данные, генерирую текст, добавляю в финальный датасет\n",
        "text_gpt2, df = process_df(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gGQIe1DTen2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('texts_to_gpt2.txt', 'w', encoding='utf-8') as f:\n",
        "        for item in text_gpt2:\n",
        "            f.write('{}\\n'.format(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7hYttYgURNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0t15aJBMcHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEikjrAfMfOb",
        "colab_type": "code",
        "outputId": "58053979-462e-4d65-ef5a-1ceab3dd0ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "len(text_gpt2), text_gpt2[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,\n",
              " 'HAMBURG, Germany, June 3 \\x97 As he left the soccer field after a club match in the eastern German city of Halle on March 25, the Nigerian forward Adebowale Ogungbure was spit upon, jeered with racial remarks and mocked with monkey noises.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWv3UTTQo7_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_gpt2[-1], df.text.tolist()[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouwuKBZKUaOA",
        "colab_type": "code",
        "outputId": "17d55a49-0377-4c75-98ea-a26bfa646b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "clean_data(text_gpt2[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-a6a0677acfbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_gpt2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-c13ce74ac1fd>\u001b[0m in \u001b[0;36mclean_data\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\s{2,10}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\s{2,10}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\\\x\\d{1,4}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, pattern)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0;32m--> 416\u001b[0;31m                            not nested and not items))\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\\\\\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_escape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0msubpatternappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/sre_parse.py\u001b[0m in \u001b[0;36m_escape\u001b[0;34m(source, escape, state)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mescape\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHEXDIGITS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"incomplete escape %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mescape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLITERAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"u\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mistext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: incomplete escape \\x at position 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohmwbm0lpjYb",
        "colab_type": "text"
      },
      "source": [
        "# Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDx8PaUgpf3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 25\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yC9XGbRq0Wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sentence(text, tokenizer, model):\n",
        "    generated = tokenizer.encode(text)\n",
        "    initial_length = len(generated)\n",
        "    context = torch.tensor([generated])\n",
        "    past = None\n",
        "\n",
        "    for i in range(MAX_LENGTH):\n",
        "        output, past = model(context, past=past)\n",
        "        token = torch.argmax(output[0, :])\n",
        "\n",
        "        generated += [token.tolist()]\n",
        "        context = token.unsqueeze(0)\n",
        "        if (tokenizer.decode(token.tolist()) in ['!', '?', '.']) and (len(generated) - initial_length > 2):\n",
        "            break\n",
        "    sequence = tokenizer.decode(generated)\n",
        "    return sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaDP6ClJvJ73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_fake(texts, fake=[], real=[], df=df, tokenizer=tokenizer, model=model):\n",
        "    i = 0\n",
        "    for ind, el in tqdm(enumerate(texts)):\n",
        "        try:\n",
        "            sent = generate_sentence(el, tokenizer=tokenizer, model=model)\n",
        "            sent = re.sub(r'\\n', '', sent)\n",
        "            fake.append(sent)\n",
        "            real.append(df.text.tolist()[ind])\n",
        "        except:\n",
        "            i+=1\n",
        "        if i % 1000 == 0:\n",
        "            print(i, 'out of', ind,' are not found in emb dict')    \n",
        "\n",
        "    with open('fake.txt', 'w', encoding='utf-8') as f:\n",
        "        for item in fake:\n",
        "            f.write('{}\\n'.format(item))\n",
        "    with open('real.txt', 'w', encoding='utf-8') as f:\n",
        "        for item in real:\n",
        "            f.write('{}\\n'.format(item))\n",
        "    return fake, real"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l1kw3dQ6GyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fake, real = make_fake(text_gpt2, fake=fake, real=real) #Если нет real и fake - убрать из параметров"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1aZgMNALhs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(fake), len(real)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaEZYDvoy4ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Запустить, если в датафрейме появляются лишние строчки с \\n (всегда)\n",
        "fake = [re.sub(r'\\n', '', line) for line in fake]\n",
        "real = [re.sub(r'\\n', '', line) for line in real]\n",
        "with open('fake.txt', 'w', encoding='utf-8') as f:\n",
        "        for item in fake:\n",
        "            f.write('{}\\n'.format(item))\n",
        "with open('real.txt', 'w', encoding='utf-8') as f:\n",
        "    for item in real:\n",
        "        f.write('{}\\n'.format(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efQg13TbLkLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fake[0], real[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbIyQNPNMsNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fake[-1], real[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z4fRXKLw9zi",
        "colab_type": "text"
      },
      "source": [
        "# To DF and CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_zc_QyPxGWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataframe(df, fake, real, df_concat=None):\n",
        "    \n",
        "    fake = open_file(fake) if type(fake) == str else fake\n",
        "    \n",
        "    real = open_file(real) if type(real) == str else real\n",
        "    new_df = pd.DataFrame()\n",
        "    new_df['text'] = real + fake\n",
        "    new_df['label'] = ['real'] * len(real) + ['fake'] * len(fake)\n",
        "    \n",
        "    if df_concat is not None:\n",
        "       new_df = pd.concat([df_concat, new_df])\n",
        "    return new_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYypdiYa5hWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df = make_dataframe(df, 'fake.txt', 'real.txt')\n",
        "final_df.to_csv(\"dataset.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcUmtOJHNHzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPgnwgTRNK1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EPSubU_jEP-",
        "colab_type": "text"
      },
      "source": [
        "# Data - Сразу сюда, когда есть final_df и dataset.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqz2PutUL8l6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Запускать если нужен готовый датафрейм (final_df) и файл dataset.csv, без генерации чего либо, сразу модель запускать\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "idd = '1goRkFXGEyrBoDuxfnDvmpHL3QQNM4AWK'\n",
        "downloaded_ = drive.CreateFile({'id':idd}) \n",
        "downloaded_.GetContentFile('dataset.csv')\n",
        "\n",
        "downloaded_ = drive.CreateFile({'id':'1HmV7mhKV7bS3TsEEgAe60oMoh8pvS7IS'}) \n",
        "downloaded_.GetContentFile('fake.txt')\n",
        "\n",
        "downloaded_ = drive.CreateFile({'id':'1vRBk1xOkRumOavk1RZdTIFI_SebrLCBW'}) \n",
        "downloaded_.GetContentFile('real.txt')\n",
        "\n",
        "fake = open_file('fake.txt')\n",
        "real = open_file('real.txt')\n",
        "\n",
        "final_df = pd.read_csv('dataset.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33sRp6h7fcNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(text):\n",
        "    return [tok.lemma_ for tok in spacy_en.tokenizer(text) if (tok.text.isalpha() or tok.text.isdigit())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz5pDXWEf7vV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = list(final_df['text'].apply(tokenizer))\n",
        "model = Word2Vec(text, size=100, iter=10) #building emb of size 100\n",
        "model_weights = torch.FloatTensor(model.wv.vectors)\n",
        "model.wv.save_word2vec_format('pretrained_embeddings')\n",
        "vectors = Vectors(name='pretrained_embeddings', cache='./') #and saving the weights to build vocab later"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga1CY5-Bf-Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 50000\n",
        "classes={'fake': 0, 'real': 1}\n",
        "\n",
        "\n",
        "TEXT = Field(sequential=True, include_lengths=False, batch_first=True, tokenize=tokenizer, \n",
        "             pad_first=True, lower=True, eos_token='<eos>') \n",
        "LABEL = LabelField(dtype=torch.float, use_vocab=True, preprocessing=lambda x: classes[x])\n",
        "\n",
        "\n",
        "dataset = TabularDataset('dataset.csv', \n",
        "                                format='csv', fields=[('text', TEXT), ('label',LABEL),], \n",
        "                                skip_header=True)\n",
        "\n",
        "TEXT.build_vocab(dataset, vectors=vectors,\n",
        "                   unk_init = torch.Tensor.normal_, max_size=MAX_VOCAB_SIZE, min_freq=2)\n",
        "LABEL.build_vocab(dataset)\n",
        "vocab = TEXT.vocab\n",
        "print('Vocab size:', len(TEXT.vocab.itos))\n",
        "TEXT.vocab.itos[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkj2Dncof_o-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = dataset.split(0.8, stratified=True)\n",
        "train, valid = train.split(0.8, stratified=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jme39KlXi_tZ",
        "colab_type": "text"
      },
      "source": [
        "# Model  - simple BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMABaZ6vgGhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.embedding.weight.data.copy_(vocab.vectors)\n",
        "        self.rnn = nn.LSTM(input_size=embed_size,\n",
        "                           hidden_size=hidden_size,\n",
        "                           bidirectional=True,\n",
        "                           batch_first=True,\n",
        "                          )\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size * 2 *2, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "           \n",
        "        _, (hidden, cell) = self.rnn(x)\n",
        "        \n",
        "        hidden = hidden.transpose(0,1)\n",
        "        cell = cell.transpose(0,1)\n",
        "        hidden = hidden.contiguous().view(hidden.size(0),-1)\n",
        "        cell = cell.contiguous().view(cell.size(0),-1)\n",
        "        x = torch.cat([hidden, cell], dim=1).squeeze(1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97CoHSWVgQTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "model = MyModel(len(TEXT.vocab.itos),\n",
        "                embed_size=100,\n",
        "                hidden_size=128,\n",
        "               )\n",
        "model.embedding.weight.data.copy_(TEXT.vocab.vectors);\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train, valid, test),\n",
        "    batch_sizes=(batch_size, batch_size, batch_size),\n",
        "    shuffle=True,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    sort_within_batch=True,\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, verbose=True, cooldown=5)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gh595PtgUKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_score(preds, y):\n",
        "    preds = torch.round(torch.sigmoid(preds))\n",
        "    preds = (preds == y).float()\n",
        "    accuracy = preds.sum() / len(preds)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25q_C7cugbw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, test_iterator):\n",
        "    test_acc = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for item in test_iterator:\n",
        "            x = item.text\n",
        "            y = item.label\n",
        "            preds = model(x).squeeze(1)\n",
        "            test_acc.append(accuracy_score(preds, y))\n",
        "    test_acc = np.mean(test_acc) \n",
        "    return np.mean(test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpAArkBZgezQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_cnn(model, train_iterator, valid_iterator, criterion, n_epochs=20):\n",
        "    \n",
        "    history = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = []\n",
        "        train_acc = []\n",
        "        model.train()\n",
        "\n",
        "    \n",
        "        for item in tqdm(train_iterator):\n",
        "            x = item.text\n",
        "            y = item.label\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(x).squeeze(1)\n",
        "            loss = criterion(preds, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.data.detach().item())\n",
        "            train_acc.append(accuracy_score(preds, y))\n",
        "\n",
        "        train_loss = np.mean(train_loss)\n",
        "        train_acc = np.mean(train_acc)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = []\n",
        "        val_acc = []\n",
        "        for item in valid_iterator:\n",
        "            x = item.text\n",
        "            y = item.label\n",
        "            preds = model(x).squeeze(1)\n",
        "            loss = criterion(preds, y)\n",
        "            val_loss.append(loss.data.detach().item())\n",
        "            val_acc.append(accuracy_score(preds, y))\n",
        "        val_loss = np.mean(val_loss)\n",
        "        val_acc = np.mean(val_acc)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "\n",
        "        print('Epoch: {}. Train loss: {:.3f}. Train accuracy: {:.3f}. Val loss: {:.3f}. Val accuracy: {:.3f}'.format(\n",
        "            epoch, train_loss, train_acc, val_loss, val_acc))        \n",
        "        \n",
        "        history.append({\n",
        "            'epoch': epoch,\n",
        "            'train_loss': train_loss,\n",
        "            'train_acc': train_acc,\n",
        "            'val_acc': val_acc,\n",
        "            'val_loss': val_loss\n",
        "        })\n",
        "\n",
        "        #if epoch % 5 == 0:\n",
        "            #torch.save(model.state_dict(), '/content/model_test')\n",
        "\n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeabQspxiOT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_tqdm():\n",
        "    for instance in list(tqdm._instances): \n",
        "        tqdm._decr_instances(instance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBdu82gkPo8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_tqdm()\n",
        "history = train_cnn(model, train_iterator, valid_iterator,\n",
        "          criterion, n_epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRrJtgyJiVSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy = test_model(model, test_iterator)\n",
        "print('Test accuracy: {}'.format(np.mean(test_accuracy)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_1s2XHPNR6QF",
        "colab": {}
      },
      "source": [
        "plt.plot([x['val_loss'] for x in history], label='Val loss')\n",
        "plt.plot([x['train_loss'] for x in history], label='Train loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj5b_CKri4-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot([x['val_acc'] for x in history], label='Val acc')\n",
        "plt.plot([x['train_acc'] for x in history], label='Train acc')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}